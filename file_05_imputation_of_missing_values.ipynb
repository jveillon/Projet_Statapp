{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries import"
      ],
      "metadata": {
        "id": "SvwGfP9nNfor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fancyimpute"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ttJ1BYfYq4o",
        "outputId": "0219927a-f8f1-45d8-f67e-afab8fc29441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fancyimpute\n",
            "  Downloading fancyimpute-0.7.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting knnimpute>=0.1.0\n",
            "  Downloading knnimpute-0.1.0.tar.gz (8.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.9/dist-packages (from fancyimpute) (1.2.2)\n",
            "Requirement already satisfied: cvxpy in /usr/local/lib/python3.9/dist-packages (from fancyimpute) (1.3.1)\n",
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.9/dist-packages (from fancyimpute) (1.3.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.9/dist-packages (from fancyimpute) (7.2.2)\n",
            "Collecting nose\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.9/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.24.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.1.1)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from cvxpy->fancyimpute) (0.6.2.post0)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.9/dist-packages (from cvxpy->fancyimpute) (2.0.12)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.9/dist-packages (from cvxpy->fancyimpute) (3.2.2)\n",
            "Requirement already satisfied: setuptools>65.5.1 in /usr/local/lib/python3.9/dist-packages (from cvxpy->fancyimpute) (67.6.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.9/dist-packages (from pytest->fancyimpute) (2.0.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from pytest->fancyimpute) (2.0.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.9/dist-packages (from pytest->fancyimpute) (1.0.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.9/dist-packages (from pytest->fancyimpute) (22.2.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.9/dist-packages (from pytest->fancyimpute) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from pytest->fancyimpute) (23.0)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.9/dist-packages (from osqp>=0.4.1->cvxpy->fancyimpute) (0.1.5.post3)\n",
            "Building wheels for collected packages: fancyimpute, knnimpute\n",
            "  Building wheel for fancyimpute (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fancyimpute: filename=fancyimpute-0.7.0-py3-none-any.whl size=29898 sha256=e668b64fa945d1ab9e00611ec260b0ab2c9b3d8781dea0d65e0ea0c35be6b0be\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/fc/6a/b0406b906bce293abe23c3b6da5a72637d2d04146ef1125a0b\n",
            "  Building wheel for knnimpute (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for knnimpute: filename=knnimpute-0.1.0-py3-none-any.whl size=11352 sha256=b4fdd0181802b824683d0b1c95dec224b3036c98630291627f3caaa0756b7886\n",
            "  Stored in directory: /root/.cache/pip/wheels/88/c4/be/e232c750d9bc360abf9a5e2cafe0d3e08e3605d2801bb11684\n",
            "Successfully built fancyimpute knnimpute\n",
            "Installing collected packages: nose, knnimpute, fancyimpute\n",
            "Successfully installed fancyimpute-0.7.0 knnimpute-0.1.0 nose-1.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Import to find the wave related to each variable\n",
        "import re\n",
        "\n",
        "# Import to preprocess the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Imports to impute missing values\n",
        "from fancyimpute import IterativeImputer\n",
        "import scipy\n",
        "\n",
        "# Imports to plot pretty graphs\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "uw94QCYxNiU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data import"
      ],
      "metadata": {
        "id": "tUduLQVTN44A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Statapp/data_dummies.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXKY2TldN7Kl",
        "outputId": "73eb303c-622f-46c4-d54b-b8ee8344db6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-9f71bf1ad93a>:1: DtypeWarning: Columns (6930) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv(\"/content/drive/MyDrive/Statapp/data_dummies.csv\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info(memory_usage=\"deep\")"
      ],
      "metadata": {
        "id": "Fm1IX8fIUW7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "section_A_or_E = data[\"genetic_Section_A_or_E\"]\n",
        "data = data.drop(columns = [\"genetic_Section_A_or_E\"]) # We drop of this useless variable."
      ],
      "metadata": {
        "id": "vxZ6G-wkWDMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Iterative imputation"
      ],
      "metadata": {
        "id": "gqCy84yoUnsU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start by dividing the dataset into smaller ones, representing each wave.\n",
        "We will impute missing values related to each wave separately."
      ],
      "metadata": {
        "id": "B2li1Z7TUsOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wave(data, wave):\n",
        "  \"\"\"\n",
        "  This function returns a smaller dataset summarizing all data for the given wave.\n",
        "\n",
        "  Note that it also returns columns that are not relative to any wave (for instance, 'HHIDPN')\n",
        "  \"\"\"\n",
        "\n",
        "  assert wave in range(1, 15)\n",
        "\n",
        "  regex = re.compile(\"[0-9]+\")\n",
        "  wave_columns = [col for col in data.columns if (len(regex.findall(col)) == 0 or regex.findall(col)[0] == str(wave))]\n",
        "  wave_data = data.loc[data[f\"INW{wave}\"] == 1, wave_columns]\n",
        "\n",
        "  return wave_data"
      ],
      "metadata": {
        "id": "kshwlNVlUqZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wave1_data = get_wave(data, 1)\n",
        "print(wave1_data.shape)\n",
        "wave1_data.head()"
      ],
      "metadata": {
        "id": "qrbpyLn6VLOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(wave1_data)\n",
        "wave1_data_scaled = scaler.transform(wave1_data)"
      ],
      "metadata": {
        "id": "TlASc0a9Cs6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To further understand how important imputation is needed, let us have a look to the part of missing values in our dataset."
      ],
      "metadata": {
        "id": "6utuSv-yHtJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For each indivudal, we count the number of missing values.\n",
        "nan_by_rows = wave1_data.isna().sum(axis=1)\n",
        "\n",
        "X = range(1, nan_by_rows.max()+1)\n",
        "Y = []\n",
        "for x in X:\n",
        "  y = (nan_by_rows <= x).sum()\n",
        "  Y.append(y)\n",
        "\n",
        "plt.plot(X, Y)\n",
        "\n",
        "plt.xlabel(\"Number of missing values\", fontsize=12)\n",
        "plt.ylabel(\"Rows\", fontsize=12)\n",
        "plt.title(\"How many rows present less or a given number of missing values\")\n",
        "\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SPCdTQhSHsqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imp_simple = SimpleImputer(strategy=\"most_frequent\")\n",
        "pd.DataFrame(imp_simple.fit_transform(wave1_data), columns = wave1_data.columns)"
      ],
      "metadata": {
        "id": "_fkMRBOQ2aoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imp = IterativeImputer(imputation_order='random', sample_posterior=True, min_value=0, max_value=1)"
      ],
      "metadata": {
        "id": "5JG1s_mNX9ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imp.fit(wave1_data_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        },
        "id": "x8D-LqRaYKUP",
        "outputId": "7602410e-adc6-430c-eb4f-2900b96e38bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IterativeImputer] Completing matrix with shape (12652, 1715)\n",
            "[IterativeImputer] Ending imputation round 1/20, elapsed time 41.40\n",
            "[IterativeImputer] Change: 213.92473732947144, scaled tolerance: 0.11247666424641158 \n",
            "[IterativeImputer] Ending imputation round 2/20, elapsed time 78.65\n",
            "[IterativeImputer] Change: 235.99570361521506, scaled tolerance: 0.11247666424641158 \n",
            "[IterativeImputer] Ending imputation round 3/20, elapsed time 114.74\n",
            "[IterativeImputer] Change: 257.64735167303746, scaled tolerance: 0.11247666424641158 \n",
            "[IterativeImputer] Ending imputation round 4/20, elapsed time 152.94\n",
            "[IterativeImputer] Change: 263.2254816218256, scaled tolerance: 0.11247666424641158 \n",
            "[IterativeImputer] Ending imputation round 5/20, elapsed time 189.40\n",
            "[IterativeImputer] Change: 259.6217561347557, scaled tolerance: 0.11247666424641158 \n",
            "[IterativeImputer] Ending imputation round 6/20, elapsed time 225.19\n",
            "[IterativeImputer] Change: 250.44236330405505, scaled tolerance: 0.11247666424641158 \n",
            "[IterativeImputer] Ending imputation round 7/20, elapsed time 262.10\n",
            "[IterativeImputer] Change: 233.96241358933318, scaled tolerance: 0.11247666424641158 \n",
            "[IterativeImputer] Ending imputation round 8/20, elapsed time 297.49\n",
            "[IterativeImputer] Change: 253.91095901124666, scaled tolerance: 0.11247666424641158 \n",
            "[IterativeImputer] Ending imputation round 9/20, elapsed time 334.56\n",
            "[IterativeImputer] Change: 257.61068480452064, scaled tolerance: 0.11247666424641158 \n",
            "[IterativeImputer] Ending imputation round 10/20, elapsed time 367.42\n",
            "[IterativeImputer] Change: 282.2493167914979, scaled tolerance: 0.11247666424641158 \n",
            "[IterativeImputer] Ending imputation round 11/20, elapsed time 399.67\n",
            "[IterativeImputer] Change: 266.12408963749317, scaled tolerance: 0.11247666424641158 \n",
            "[IterativeImputer] Ending imputation round 12/20, elapsed time 437.94\n",
            "[IterativeImputer] Change: 279.9153458541431, scaled tolerance: 0.11247666424641158 \n",
            "[IterativeImputer] Ending imputation round 13/20, elapsed time 475.61\n",
            "[IterativeImputer] Change: 329.42720316828485, scaled tolerance: 0.11247666424641158 \n",
            "[IterativeImputer] Ending imputation round 14/20, elapsed time 510.58\n",
            "[IterativeImputer] Change: 300.1848248896274, scaled tolerance: 0.11247666424641158 \n",
            "[IterativeImputer] Ending imputation round 15/20, elapsed time 548.21\n",
            "[IterativeImputer] Change: 253.76227413070913, scaled tolerance: 0.11247666424641158 \n",
            "[IterativeImputer] Ending imputation round 16/20, elapsed time 586.05\n",
            "[IterativeImputer] Change: 286.73311771235217, scaled tolerance: 0.11247666424641158 \n",
            "[IterativeImputer] Ending imputation round 17/20, elapsed time 622.59\n",
            "[IterativeImputer] Change: 314.3614573357397, scaled tolerance: 0.11247666424641158 \n",
            "[IterativeImputer] Ending imputation round 18/20, elapsed time 657.60\n",
            "[IterativeImputer] Change: 303.9791850896531, scaled tolerance: 0.11247666424641158 \n",
            "[IterativeImputer] Ending imputation round 19/20, elapsed time 693.75\n",
            "[IterativeImputer] Change: 316.1916423196518, scaled tolerance: 0.11247666424641158 \n",
            "[IterativeImputer] Ending imputation round 20/20, elapsed time 733.12\n",
            "[IterativeImputer] Change: 278.9050469056191, scaled tolerance: 0.11247666424641158 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IterativeImputer(max_iter=20, n_nearest_features=20, random_state=0, verbose=2)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IterativeImputer(max_iter=20, n_nearest_features=20, random_state=0, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">IterativeImputer</label><div class=\"sk-toggleable__content\"><pre>IterativeImputer(max_iter=20, n_nearest_features=20, random_state=0, verbose=2)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wave1_data_imputed_iterative = pd.DataFrame(scaler.inverse_transform(imp.transform(wave1_data_scaled)), columns=wave1_data.columns)\n",
        "wave1_data_imputed_iterative.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "id": "MbXFyqrZWgva",
        "outputId": "d15a0330-2290-44e3-8b55-2c12b387645d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IterativeImputer] Completing matrix with shape (12652, 1715)\n",
            "[IterativeImputer] Ending imputation round 1/20, elapsed time 1.19\n",
            "[IterativeImputer] Ending imputation round 2/20, elapsed time 2.41\n",
            "[IterativeImputer] Ending imputation round 3/20, elapsed time 3.60\n",
            "[IterativeImputer] Ending imputation round 4/20, elapsed time 4.78\n",
            "[IterativeImputer] Ending imputation round 5/20, elapsed time 5.98\n",
            "[IterativeImputer] Ending imputation round 6/20, elapsed time 7.18\n",
            "[IterativeImputer] Ending imputation round 7/20, elapsed time 8.38\n",
            "[IterativeImputer] Ending imputation round 8/20, elapsed time 9.59\n",
            "[IterativeImputer] Ending imputation round 9/20, elapsed time 10.79\n",
            "[IterativeImputer] Ending imputation round 10/20, elapsed time 12.01\n",
            "[IterativeImputer] Ending imputation round 11/20, elapsed time 13.32\n",
            "[IterativeImputer] Ending imputation round 12/20, elapsed time 14.56\n",
            "[IterativeImputer] Ending imputation round 13/20, elapsed time 15.78\n",
            "[IterativeImputer] Ending imputation round 14/20, elapsed time 17.01\n",
            "[IterativeImputer] Ending imputation round 15/20, elapsed time 18.21\n",
            "[IterativeImputer] Ending imputation round 16/20, elapsed time 19.41\n",
            "[IterativeImputer] Ending imputation round 17/20, elapsed time 20.60\n",
            "[IterativeImputer] Ending imputation round 18/20, elapsed time 21.81\n",
            "[IterativeImputer] Ending imputation round 19/20, elapsed time 23.04\n",
            "[IterativeImputer] Ending imputation round 20/20, elapsed time 24.27\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       HHIDPN    S1HHIDPN  R1MPART   S1BMONTH      S1BYEAR      S1BDATE  \\\n",
              "0      1010.0         0.0      0.0   6.486992  1937.311702 -7346.144438   \n",
              "1      2010.0         0.0      0.0   6.360719  1932.458299 -9042.863096   \n",
              "2      3010.0      3020.0      0.0   9.000000  1938.000000 -7778.000000   \n",
              "3      3020.0      3010.0      0.0   1.000000  1936.000000 -8752.000000   \n",
              "4  10001010.0         0.0      0.0   6.361757  1938.056865 -7635.164689   \n",
              "5  10003020.0  10003030.0      0.0   3.000000  1956.000000 -1387.000000   \n",
              "6  10003030.0  10003020.0      0.0   4.000000  1934.000000 -9392.000000   \n",
              "7  10004010.0  10004040.0      0.0   4.000000  1946.000000 -5009.000000   \n",
              "8  10004040.0  10004010.0      0.0  12.000000  1939.000000 -7322.000000   \n",
              "9  10013010.0  10013040.0      0.0  11.000000  1947.000000 -4430.000000   \n",
              "\n",
              "    S1BFLAG  S1HRSAMP  S1AHDSMP  S1HISPAN  ...  S1ADLW_2.0  S1ADLW_3.0  \\\n",
              "0  0.000596 -0.036304 -0.001549 -0.003114  ...    0.023267    0.016260   \n",
              "1  0.000790  0.030824 -0.011935  0.038395  ...    0.033165    0.022596   \n",
              "2  0.000000  1.000000  0.000000  0.000000  ...    0.000000    0.000000   \n",
              "3  0.000000  1.000000  0.000000  0.000000  ...    0.000000    0.000000   \n",
              "4 -0.000121  0.030907 -0.004237  0.032521  ...    0.031083    0.017436   \n",
              "5  0.000000  0.000000  0.000000  0.000000  ...    0.000000    0.000000   \n",
              "6  0.000000  1.000000  0.000000  0.000000  ...    0.000000    0.000000   \n",
              "7  0.000000  0.000000  0.000000  0.000000  ...    0.000000    0.000000   \n",
              "8  0.000000  1.000000  0.000000  0.000000  ...    0.000000    0.000000   \n",
              "9  0.000000  0.000000  0.000000  0.000000  ...    0.000000    0.000000   \n",
              "\n",
              "   S1ADLW_4.0  S1ADLW_5.0  R1ADLW_0.0  R1ADLW_1.0  R1ADLW_2.0  R1ADLW_3.0  \\\n",
              "0    0.016007    0.009874         1.0         0.0         0.0         0.0   \n",
              "1    0.020769    0.012239         1.0         0.0         0.0         0.0   \n",
              "2    0.000000    0.000000         1.0         0.0         0.0         0.0   \n",
              "3    0.000000    0.000000         1.0         0.0         0.0         0.0   \n",
              "4    0.016789    0.009350         1.0         0.0         0.0         0.0   \n",
              "5    0.000000    0.000000         1.0         0.0         0.0         0.0   \n",
              "6    0.000000    0.000000         1.0         0.0         0.0         0.0   \n",
              "7    0.000000    0.000000         0.0         1.0         0.0         0.0   \n",
              "8    0.000000    0.000000         1.0         0.0         0.0         0.0   \n",
              "9    0.000000    0.000000         1.0         0.0         0.0         0.0   \n",
              "\n",
              "   R1ADLW_4.0  R1ADLW_5.0  \n",
              "0         0.0         0.0  \n",
              "1         0.0         0.0  \n",
              "2         0.0         0.0  \n",
              "3         0.0         0.0  \n",
              "4         0.0         0.0  \n",
              "5         0.0         0.0  \n",
              "6         0.0         0.0  \n",
              "7         0.0         0.0  \n",
              "8         0.0         0.0  \n",
              "9         0.0         0.0  \n",
              "\n",
              "[10 rows x 1715 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27fe41c8-9c16-4f1a-8df5-4237b34030ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HHIDPN</th>\n",
              "      <th>S1HHIDPN</th>\n",
              "      <th>R1MPART</th>\n",
              "      <th>S1BMONTH</th>\n",
              "      <th>S1BYEAR</th>\n",
              "      <th>S1BDATE</th>\n",
              "      <th>S1BFLAG</th>\n",
              "      <th>S1HRSAMP</th>\n",
              "      <th>S1AHDSMP</th>\n",
              "      <th>S1HISPAN</th>\n",
              "      <th>...</th>\n",
              "      <th>S1ADLW_2.0</th>\n",
              "      <th>S1ADLW_3.0</th>\n",
              "      <th>S1ADLW_4.0</th>\n",
              "      <th>S1ADLW_5.0</th>\n",
              "      <th>R1ADLW_0.0</th>\n",
              "      <th>R1ADLW_1.0</th>\n",
              "      <th>R1ADLW_2.0</th>\n",
              "      <th>R1ADLW_3.0</th>\n",
              "      <th>R1ADLW_4.0</th>\n",
              "      <th>R1ADLW_5.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1010.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.486992</td>\n",
              "      <td>1937.311702</td>\n",
              "      <td>-7346.144438</td>\n",
              "      <td>0.000596</td>\n",
              "      <td>-0.036304</td>\n",
              "      <td>-0.001549</td>\n",
              "      <td>-0.003114</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023267</td>\n",
              "      <td>0.016260</td>\n",
              "      <td>0.016007</td>\n",
              "      <td>0.009874</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.360719</td>\n",
              "      <td>1932.458299</td>\n",
              "      <td>-9042.863096</td>\n",
              "      <td>0.000790</td>\n",
              "      <td>0.030824</td>\n",
              "      <td>-0.011935</td>\n",
              "      <td>0.038395</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033165</td>\n",
              "      <td>0.022596</td>\n",
              "      <td>0.020769</td>\n",
              "      <td>0.012239</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3010.0</td>\n",
              "      <td>3020.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>1938.000000</td>\n",
              "      <td>-7778.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3020.0</td>\n",
              "      <td>3010.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1936.000000</td>\n",
              "      <td>-8752.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10001010.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.361757</td>\n",
              "      <td>1938.056865</td>\n",
              "      <td>-7635.164689</td>\n",
              "      <td>-0.000121</td>\n",
              "      <td>0.030907</td>\n",
              "      <td>-0.004237</td>\n",
              "      <td>0.032521</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031083</td>\n",
              "      <td>0.017436</td>\n",
              "      <td>0.016789</td>\n",
              "      <td>0.009350</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10003020.0</td>\n",
              "      <td>10003030.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1956.000000</td>\n",
              "      <td>-1387.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10003030.0</td>\n",
              "      <td>10003020.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1934.000000</td>\n",
              "      <td>-9392.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10004010.0</td>\n",
              "      <td>10004040.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1946.000000</td>\n",
              "      <td>-5009.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10004040.0</td>\n",
              "      <td>10004010.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>1939.000000</td>\n",
              "      <td>-7322.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10013010.0</td>\n",
              "      <td>10013040.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>1947.000000</td>\n",
              "      <td>-4430.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 1715 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27fe41c8-9c16-4f1a-8df5-4237b34030ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-27fe41c8-9c16-4f1a-8df5-4237b34030ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-27fe41c8-9c16-4f1a-8df5-4237b34030ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wave1_data_imputed_iterative[\"R1ADLW_0.0\"].describe()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Db2gEsF16Jr",
        "outputId": "29515f91-3d63-4c08-e357-52b0ee3b2281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    12652.000000\n",
              "mean         0.892582\n",
              "std          0.309664\n",
              "min         -0.040536\n",
              "25%          1.000000\n",
              "50%          1.000000\n",
              "75%          1.000000\n",
              "max          1.000000\n",
              "Name: R1ADLW_0.0, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "impute_knn = KNNImputer(n_neighbors = 10)\n",
        "\n",
        "wave1_data_imputed_knn = pd.DataFrame(scaler.inverse_transform(impute_knn.fit_transform(wave1_data_scaled)), columns=wave1_data.columns)\n",
        "wave1_data_imputed_knn.head(10)"
      ],
      "metadata": {
        "id": "NzP5UH7Dk0Sz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}