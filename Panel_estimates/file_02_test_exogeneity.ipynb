{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c0307ef",
   "metadata": {},
   "source": [
    "Import of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "747ca7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler # To standardize the data\n",
    "import cvxpy as cp\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fbb11d",
   "metadata": {},
   "source": [
    "Import of the HMLasso function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e07cd446",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adapt the path \"C:/Users/Kilian/Desktop/ENSAE/STATAPP\" to run the cell\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, 'C:/Users/Kilian/Desktop/ENSAE/STATAPP/Projet_Statapp/pretreatment')\n",
    "\n",
    "import file_04_HMLasso as hml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf72f6ac",
   "metadata": {},
   "source": [
    "## Data downloading and separation of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ca111d",
   "metadata": {},
   "source": [
    "Dataset containing the types of each column from data_03.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f16325af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HHIDPN</td>\n",
       "      <td>Cont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HHID</td>\n",
       "      <td>Char</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PN</td>\n",
       "      <td>Char</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  Type\n",
       "0  HHIDPN  Cont\n",
       "1    HHID  Char\n",
       "2      PN  Char"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_types = pd.read_csv(\"data_03_columns_types.csv\", index_col=0)\n",
    "columns_types.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfbe86a",
   "metadata": {},
   "source": [
    "Downloading the data with social and genetic variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "015166c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\3952530018.py:1: DtypeWarning: Columns (2684) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"data_03.csv\")\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data_03.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aec591",
   "metadata": {},
   "source": [
    "The column \"genetic_Section_A_or_E\" have mixed types, so we change its format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "965a817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary = np.where(data['genetic_Section_A_or_E'] == 'E', 1, np.where(data['genetic_Section_A_or_E'] == 'A', 0, np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02f5d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"genetic_Section_A_or_E\"] = temporary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6b4e72",
   "metadata": {},
   "source": [
    "Now we add the health index created by t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f6a30ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tSNE_GHI = pd.read_csv(\"data_tSNE_GHI.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379fa4f3",
   "metadata": {},
   "source": [
    "We merge the t-SNE health index to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c121e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(tSNE_GHI, how ='left', on ='HHIDPN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf31a8d",
   "metadata": {},
   "source": [
    "Here we test exogeneity, so we only keep individuals who were interviewed at all waves (14 waves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3ebbb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bis = data.copy()\n",
    "\n",
    "for i in range(1,15):\n",
    "    data_bis = data_bis[data_bis['tSNE_GHI'+str(i)].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7ead7a",
   "metadata": {},
   "source": [
    "Number of individuals present in every waves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f7abd54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3396"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tSNE_GHI[~tSNE_GHI.isnull().any(axis=1)].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed04aaf5",
   "metadata": {},
   "source": [
    "We select the outcome tSNE_GHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39aa86f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data_bis[[\"HHIDPN\"]+[\"tSNE_GHI\" + str(i) for i in range (1,15)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c563e1a",
   "metadata": {},
   "source": [
    "We drop the previous health index GHIw from the data, which won't be used as outcome.\n",
    "(list_columns_GHI contains the names of GHIw columns).\n",
    "\n",
    "We drop the outcome to create the matrix X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "559e8cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_bis.drop([\"GHI\" + str(i) for i in range (1,15)], axis = 1)\n",
    "X.drop([\"tSNE_GHI\" + str(i) for i in range (1,15)], axis = 1, inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f228abcf",
   "metadata": {},
   "source": [
    "Now we split the dataset into training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bebb3e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=18)\n",
    "X_test, X_valid, Y_test, Y_valid = train_test_split(X_test, Y_test, test_size=0.5, random_state = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ddedcf",
   "metadata": {},
   "source": [
    "## Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46496dbf",
   "metadata": {},
   "source": [
    "The objective here is to make a dataset where we observe if each variable exists at each wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cde8436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_temporal_variables (X_train,add_tSNE_GHIw):   \n",
    "    temporal_variables = {}\n",
    "    waves_columns = [col for col in X_train.columns if \"genetic_\" not in col and col[1] in \"123456789\"]\n",
    "    for col in waves_columns:\n",
    "      char = col[0] # R or H\n",
    "      if col[2] in \"01234\":\n",
    "        wave = col[1:3]\n",
    "        suffix = col[3:]\n",
    "      else:\n",
    "        wave = col[1]\n",
    "        suffix = col[2:]\n",
    "      variable = char + 'w' + suffix\n",
    "\n",
    "      if variable not in temporal_variables.keys():\n",
    "        temporal_variables[variable] = np.zeros((14), dtype=bool)\n",
    "\n",
    "      temporal_variables[variable][int(wave)-1] = True\n",
    "\n",
    "    temporal_variables = pd.DataFrame(temporal_variables)\n",
    "\n",
    "    # We manually add \"tSNE_GHIw\":\n",
    "    if add_tSNE_GHIw and \"tSNE_GHI1\":\n",
    "        temporal_variables[\"tSNE_GHIw\"] = np.ones((14), dtype=bool)\n",
    "        waves_columns += [f\"tSNE_GHI{w}\" for w in range(1,15)]\n",
    "        \n",
    "    return (temporal_variables,waves_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8869d3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeless data\n",
    "def timeless_variables(X_train,waves_columns):\n",
    "    non_waves_columns = [col for col in X_train.columns if col not in waves_columns]\n",
    "    To_remove = [\"HHIDPN\",\"PN\",\"HHID\",\"RAHHIDPN\",'genetic_VERSION','genetic_Section_A_or_E']+[\"INW\"+str(i+1) for i in range (14)]\n",
    "    for x in To_remove:\n",
    "        if x in non_waves_columns:\n",
    "            non_waves_columns.remove(x)\n",
    "    return non_waves_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184b3d71",
   "metadata": {},
   "source": [
    "We put the explaining variables by wave in a list of dataset Intemporal variables are put in each one of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3fbfdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def list_wave(X_train, reduced, gen_var):\n",
    "    (temporal_variables , waves_columns) = dataset_temporal_variables(X_train,True)\n",
    "    non_waves_columns = timeless_variables(X_train,waves_columns)\n",
    "    \n",
    "    non_waves_columns_no_genetic = [var for var in non_waves_columns if not('genetic_' in var)]\n",
    "    \n",
    "    #Reduce number of variables to code\n",
    "    if reduced:\n",
    "        temporal_variables_2 = temporal_variables.iloc[:,[i for i in range(1,15)]+[-i for i in range(1,5)]]\n",
    "        non_waves_columns_2 = random.choices(non_waves_columns,k=5)\n",
    "        non_waves_columns_no_genetic_2 = random.choices(non_waves_columns_no_genetic,k=5)\n",
    "\n",
    "        liste = [] \n",
    "        for i in range(14):\n",
    "            columns_wave_i = [\"HHIDPN\"]+[col.replace('w', str(i+1)) for col in temporal_variables_2.T[i].index[temporal_variables_2.T[i]] if col != \"tSNE_GHIw\"]\n",
    "            #Add the intemporal variables only to the last wave, to avoid duplicated labels issues\n",
    "            if i ==  13 and gen_var:\n",
    "                liste.append(X_train.loc[X_train[\"INW\"+str(i+1)] == 1, columns_wave_i + non_waves_columns_2])\n",
    "            elif i == 13:\n",
    "                liste.append(X_train.loc[X_train[\"INW\"+str(i+1)] == 1, columns_wave_i + non_waves_columns_no_genetic_2])\n",
    "            else:\n",
    "                liste.append(X_train.loc[X_train[\"INW\"+str(i+1)] == 1, columns_wave_i])\n",
    "                \n",
    "    #All the variables\n",
    "    else:\n",
    "        liste = []    # len = 14 \n",
    "        for i in range(14):\n",
    "            columns_wave_i = [\"HHIDPN\"]+[col.replace('w', str(i+1)) for col in temporal_variables.T[i].index[temporal_variables.T[i]] if col != \"tSNE_GHIw\"]\n",
    "            #Intemporal variables only to the last wave, to avoid duplicated labels issues\n",
    "            if i ==  13 and gen_var:\n",
    "                liste.append(X_train.loc[X_train[\"INW\"+str(i+1)] == 1, columns_wave_i + non_waves_columns])\n",
    "            elif i == 13:\n",
    "                liste.append(X_train.loc[X_train[\"INW\"+str(i+1)] == 1, columns_wave_i + non_waves_columns_no_genetic])\n",
    "            else:\n",
    "                liste.append(X_train.loc[X_train[\"INW\"+str(i+1)] == 1, columns_wave_i])\n",
    "                \n",
    "    return (liste)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea850340",
   "metadata": {},
   "source": [
    "### Lasso selection\n",
    "\n",
    "We start to initialize with a first lasso on the first wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6c57b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_Lasso(liste, Y_train, HMLasso, method, mu, limit,print_wave):\n",
    "    \n",
    "    if print_wave:\n",
    "        print(\"wave\",1)\n",
    "    \n",
    "    scaler = StandardScaler()#(with_std=False)\n",
    "    hml.ERRORS_HANDLING = \"ignore\"\n",
    "    \n",
    "    #Prepare data\n",
    "    Y_train1 = Y_train.iloc[:,[0,1]]\n",
    "    Y_columns = Y_train1.columns\n",
    "    Y_train1.dropna(axis =0, inplace =True)\n",
    "    X_Y_tempo = liste[0].merge(Y_train1, how = \"left\", on = \"HHIDPN\")\n",
    "    X_train1 = X_Y_tempo.drop(Y_columns, axis=1)\n",
    "    Y_train1 = X_Y_tempo[Y_train1.columns[0]]\n",
    "    Y_train1 = Y_train1.values\n",
    "    Y_train1 = (Y_train1 - np.mean(Y_train1))/np.std(Y_train1)\n",
    "    \n",
    "  \n",
    "    #HMLasso\n",
    "    if HMLasso:\n",
    "        #Standardize X_train\n",
    "        X_train1 = scaler.fit_transform(X_train1)\n",
    "        \n",
    "        coefficients = apply_HMLasso(X_train1, Y_train1,mu)\n",
    "        \n",
    "        #Variables to keep\n",
    "        var_to_keep = coefficients > 10**(limit)\n",
    "    \n",
    "    #Common Lasso\n",
    "    else:\n",
    "        X_train1 = Na_imputation(X_train1, method)\n",
    "        \n",
    "        #Standardize X_train\n",
    "        X_train1 = scaler.fit_transform(X_train1)\n",
    "        \n",
    "        (coefficients, Resid) = apply_Lasso(X_train1, Y_train1, mu)\n",
    "        \n",
    "        #Variables top keep\n",
    "        var_to_keep = coefficients != 0\n",
    "        \n",
    "        \n",
    "\n",
    "    #Selection of variables\n",
    "    if print_wave:\n",
    "        print(\"Variables kept :\", list(var_to_keep).count(1))\n",
    "    var_to_keep = np.insert(var_to_keep,0,True)\n",
    "    \n",
    "    entire_data = liste[0]\n",
    "    selected = entire_data[entire_data.columns[var_to_keep]]\n",
    "        \n",
    "    return (selected,Resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fb6de6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_HMLasso(X, Y, mu):\n",
    "    \n",
    "    lasso = hml.HMLasso(mu)\n",
    "    lasso.fit(X, Y)\n",
    "    \n",
    "    coefficients = np.abs(lasso.beta_opt.copy())\n",
    "    \n",
    "    return coefficients\n",
    "\n",
    "def apply_Lasso(X,Y, mu):\n",
    "    \n",
    "    clf = linear_model.Lasso(alpha=mu)\n",
    "    clf.fit(X, Y)\n",
    "    \n",
    "    coefficients = clf.coef_\n",
    "    \n",
    "    #Correlation between residuals and X\n",
    "    Y_hat = clf.predict(X)\n",
    "    Resid = Y - Y_hat\n",
    "    \n",
    "    return (coefficients, Resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f49142c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Na_imputation(X, method):\n",
    "    if method == \"mean\":\n",
    "        return X.fillna(X.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9394e1",
   "metadata": {},
   "source": [
    "function to impute missing data created when merging by mean but without touching Na values already there before the merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ab72eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Na_management(df1, df2, index):\n",
    "    \n",
    "    merged = df1.merge(df2, how='outer', on = index)\n",
    "    \n",
    "    df1_index = df1.set_index(index)\n",
    "    df2_index = df2.set_index(index)\n",
    "    \n",
    "    merged = merged.fillna(merged.mean())\n",
    "    merged = merged.set_index(index)\n",
    "    \n",
    "    df1_index = df1_index.fillna(\"NaN\")\n",
    "    merged.update(df1_index)\n",
    "    \n",
    "    df2_index = df2_index.fillna(\"NaN\")\n",
    "    merged.update(df2_index)\n",
    "    \n",
    "    merged = merged.replace(\"NaN\",np.nan)\n",
    "    \n",
    "    merged = merged.reset_index()\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a387d69",
   "metadata": {},
   "source": [
    "Function to select variables by HMLasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "539e1965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lasso_selection(X_train, Y_train, HMLasso, method, mu, limit, reduced, print_wave, gen_var):\n",
    "    \n",
    "    #If a columns contains only Nan values, we drop it\n",
    "    empty_col = [col for col in X_train.columns if X_train[col].isnull().all()]\n",
    "    if empty_col != []:\n",
    "        X_train.drop(empty_col, axis=1, inplace=True)\n",
    "    \n",
    "    liste = list_wave(X_train, reduced, gen_var)\n",
    "    \n",
    "    if print_wave:\n",
    "        print(\"Lasso selection, mu =\", mu)\n",
    "    \n",
    "    \n",
    "    (selected, Wave_1) = initialize_Lasso(liste, Y_train, HMLasso, method, mu, limit,print_wave)\n",
    "    \n",
    "    Residuals = pd.DataFrame({\"Wave_1\" : Wave_1})\n",
    "    \n",
    "    print(Residuals)\n",
    "    \n",
    "    scaler = StandardScaler()#(with_std=False)\n",
    "    hml.ERRORS_HANDLING = \"ignore\"\n",
    "    \n",
    "    for i in range (1,14) :\n",
    "        \n",
    "        if print_wave:\n",
    "            print(\"wave\",i+1)\n",
    "\n",
    "        var_to_select = Na_management(selected, liste[i], \"HHIDPN\")\n",
    "\n",
    "        Y_train_i = Y_train.iloc[:,[0,i+1]]\n",
    "        Y_columns = Y_train_i.columns\n",
    "        X_Y_train = var_to_select.merge(Y_train_i, how = 'left', on = \"HHIDPN\")\n",
    "\n",
    "        Y_train_i = X_Y_train[Y_columns[0]]\n",
    "        X_train_i = X_Y_train.drop(Y_columns, axis =1)\n",
    "\n",
    "        Y_train_i = Y_train_i.fillna(Y_train_i.mean())\n",
    "        Y_train_i = Y_train_i.values\n",
    "        Y_train_i = (Y_train_i - np.mean(Y_train_i))/np.std(Y_train_i)\n",
    "\n",
    "        \n",
    "        #HMLasso\n",
    "        if HMLasso:\n",
    "            #Standardize X_train\n",
    "            X_train_i = scaler.fit_transform(X_train_i)\n",
    "        \n",
    "            coefficients = apply_HMLasso(X_train_i, Y_train_i, mu)\n",
    "        \n",
    "            #Variables to keep\n",
    "            var_to_keep = coefficients > 10**(limit)\n",
    "            \n",
    "        #Common Lasso\n",
    "        else:\n",
    "            X_train_i = Na_imputation(X_train_i, method)\n",
    "        \n",
    "            #Standardize X_train\n",
    "            X_train_i = scaler.fit_transform(X_train_i)\n",
    "\n",
    "            (coefficients, resid) = apply_Lasso(X_train_i, Y_train_i, mu)\n",
    "            \n",
    "            Residuals[\"Wave_\"+str(i+1)] = resid\n",
    "            #Variables top keep\n",
    "            var_to_keep = coefficients != 0\n",
    "            \n",
    "        #Selection of variables\n",
    "        if print_wave:\n",
    "            print(\"Variables kept :\", list(var_to_keep).count(1))\n",
    "        var_to_keep = np.insert(var_to_keep,0,True)\n",
    "\n",
    "        entire_data = var_to_select\n",
    "        selected = entire_data[entire_data.columns[var_to_keep]] \n",
    "        \n",
    "    Test = test_resid(liste, Residuals)\n",
    "    \n",
    "    #Return the data with selected variables, the number of variables selected and the names of columns\n",
    "    return (selected, selected.columns, Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5ff3329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "def test_resid(liste, residuals):\n",
    "    #start by separating residuals in temporal residuals and non temporal\n",
    "    columns_r = residuals.columns\n",
    "    residuals[\"MEAN\"] = residuals[columns_r].sum(axis=1)/14\n",
    "    TEST = []\n",
    "    for k in range(0, 14): \n",
    "        Test = pd.DataFrame()\n",
    "        X_t = liste[k]\n",
    "        X_t = X_t.fillna(X_t.mean())\n",
    "        P_stat , p_value = [] , []\n",
    "        noms = [x for x in X_t.columns if x != \"HHIDPN\"]\n",
    "        for j in range(0,14):\n",
    "            for x in X_t.columns:\n",
    "                P_test = list(pearsonr(X_t[x],residuals[\"Wave_\"+str(j+1)]))\n",
    "                P_stat.append(P_test[0])\n",
    "                p_value.append(P_test[1])\n",
    "                Test = pd.DataFrame(data = { 'Correlation' : P_stat , 'p_value' : p_value})\n",
    "            TEST.append(Test)\n",
    "    return TEST\n",
    "                \n",
    "  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b3ff18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = np.array([1,2])\n",
    "K = [3,4]\n",
    "M =[L,K]\n",
    "L - 2\n",
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b605b486",
   "metadata": {},
   "source": [
    "### Within estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966cba15",
   "metadata": {},
   "source": [
    "There two types of missing values, the \"one-time\" missing values when someone didn't awnser a question during the interview or so and the missing values when someone wasn't interviewed at all during a wave.\n",
    "\n",
    "\n",
    "For the first type, we impute those missing values with the mean of the column (Nan).\n",
    "(Possibility to work on another imputation method).\n",
    "\n",
    "Then for the individuals who weren't interviewed during a wave, we replace the missing value with the temporal mean of the variable over time (NanNan)\n",
    "\n",
    "\n",
    "Finally, we compute X_vague_ti = X_ti - temporal_mean(X_ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2ba7254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creation_data_within(selected, Lasso_before_within):\n",
    "    \n",
    "    if not(Lasso_before_within):\n",
    "        selected = selected.drop([\"INW\"+str(i) for i in range(1,15)], axis =1)\n",
    "    #For the \"one-time\" missing values imputation by mean\n",
    "    X_train_within = selected.fillna(selected.mean())\n",
    "    ###For people who weren't interviewed\n",
    "    \n",
    "    # We start by adding the INWw columns to know if the individual was interviewed during the wave w\n",
    "    X_train_within = X_train_within.merge(X_train[[\"HHIDPN\"]+[\"INW\"+str(i) for i in range(1,15)]], how =\"left\", on=\"HHIDPN\")  \n",
    "\n",
    "    #We recover the missing values for people who weren't interviewed during the wave w\n",
    "    X_train_within = recover_missing(X_train_within)\n",
    "    \n",
    "    # Creation of the data set for within regression.\n",
    "    (X_train_within, temporal_variables_within) = data_set_within(X_train_within)\n",
    "    \n",
    "    #Still Nan values in intemporal variables\n",
    "    X_train_within = X_train_within.fillna(X_train_within.mean())\n",
    "    \n",
    "    return (X_train_within, temporal_variables_within)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feface31",
   "metadata": {},
   "source": [
    "This function return a dataset containing only variables concerned by the wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "464508b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "\n",
    "def get_wave(data, wave, non_temporal):\n",
    "  \"\"\"\n",
    "  This function returns a smaller dataset summarizing all data for the given wave.\n",
    "\n",
    "  Note that it also returns columns that are not relative to any wave (for instance, 'HHIDPN')\n",
    "  \"\"\"\n",
    "\n",
    "  assert wave in range(1, 15)\n",
    "\n",
    "  regex = re.compile(\"[0-9]+\")\n",
    "  if non_temporal:\n",
    "        wave_columns = [col for col in data.columns if (len(regex.findall(col)) == 0 or regex.findall(col)[0] == str(wave))]\n",
    "  else:\n",
    "        wave_columns = [col for col in data.columns if (regex.findall(col) != [] and regex.findall(col)[0] == str(wave))]\n",
    "  wave_data = data[wave_columns]\n",
    "\n",
    "  return wave_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cf1ef0",
   "metadata": {},
   "source": [
    "Function to recover the missing values for people who weren't interviewed during the wave w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd5b9229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_missing(X_train_within):\n",
    "\n",
    "    X_train_within_index = X_train_within.set_index(\"HHIDPN\")\n",
    "    wave_1 = get_wave(X_train_within_index,1, non_temporal =False)\n",
    "    wave_1.loc[wave_1[\"INW1\"] == 0] = np.nan\n",
    "    wave_1[\"INW1\"].fillna(0)\n",
    "    Tempo = wave_1\n",
    "\n",
    "    for i in range(2,15):\n",
    "        if i == 14:\n",
    "            wave_i = get_wave(X_train_within_index, i, non_temporal =True)\n",
    "        else:\n",
    "            wave_i = get_wave(X_train_within_index, i, non_temporal =False)\n",
    "        wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
    "        wave_i[\"INWw\".replace('w', str(i))].fillna(0)\n",
    "        Tempo = Tempo.merge(wave_i, how= \"left\", on = \"HHIDPN\")\n",
    "\n",
    "    return Tempo.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de283800",
   "metadata": {},
   "source": [
    "Get a dataframe to know which variables are in X_train_within"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c4691c",
   "metadata": {},
   "source": [
    "Function to compute (A faire en latex) X_vague_ti = X_ti - temporal_mean(X_ti) if the temporal variable is present in at least two waves.\n",
    "\n",
    "It creates columns containing the temporal mean of a temporal variables and then replaces the Nan values (when people weren't interviewed) by this mean. Finally it creates the dataset  X_vague_ti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d188ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_set_within (X_train_within):\n",
    "    \n",
    "    temporal_variables_within = dataset_temporal_variables(X_train_within, False)[0]\n",
    "    \n",
    "    X_within = X_train_within.copy()\n",
    "    temporal_variables_within_actualised = temporal_variables_within.copy()\n",
    "    i = 0\n",
    "    \n",
    "    for col in temporal_variables_within.columns:\n",
    "        i += 1\n",
    "        if i%10 == 0:\n",
    "            print(i, \"out of \", len(temporal_variables_within.columns))\n",
    "        index_wave = temporal_variables_within.index[temporal_variables_within[col]==1].tolist()\n",
    "        names_waves = [col.replace('w', str(i+1)) for i in index_wave]\n",
    "        \n",
    "        # Only if the temporal variable is present in at least two waves\n",
    "        if len(names_waves)>1:\n",
    "            # (~X_within[names_waves].isna()).sum(axis=1) = number of non missing values\n",
    "            X_within[col+\"_MEAN\"] = X_within[names_waves].sum(axis=1)/(~X_within[names_waves].isna()).sum(axis=1)\n",
    "            for x in names_waves:\n",
    "                # Imputing the missing values by the temporal mean\n",
    "                X_within[x].fillna(X_within[col+\"_MEAN\"], inplace= True)         \n",
    "                #Creating the new data for within regression X_vague\n",
    "                X_within[x+\"_Within\"] = X_within[x] - X_within[col+\"_MEAN\"]\n",
    "                X_within.drop(x, inplace=True, axis=1)\n",
    "        \n",
    "        else:\n",
    "            temporal_variables_within_actualised = temporal_variables_within_actualised.drop(col, axis=1)\n",
    "    return (X_within, temporal_variables_within_actualised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3488b723",
   "metadata": {},
   "source": [
    "Now we do the same thing to Y_train but no need to impute the Nan values since the only outcome is tSNE_GHI14 (no Nan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2cae241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creation_outcome_within(Y_train):\n",
    "\n",
    "    Y_train_within = Y_train.copy()\n",
    "    \n",
    "    tSNE_GHI = [f\"tSNE_GHI{w}\" for w in range(1,15)]\n",
    "\n",
    "    Y_train_within[\"tSNE_GHIw_MEAN\"] = Y_train_within[tSNE_GHI].sum(axis=1)/(~Y_train_within[tSNE_GHI].isna()).sum(axis=1)\n",
    "    for col in tSNE_GHI:\n",
    "        Y_train_within[col+\"_within\"] = Y_train_within[col] - Y_train_within[\"tSNE_GHIw_MEAN\"]\n",
    "    \n",
    "    return Y_train_within"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95850bfa",
   "metadata": {},
   "source": [
    "We can now proceed to the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b69821c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_Y_within(X_train_within, Y_train_within, temporal_variables_within, Lasso_before_within):\n",
    "    \n",
    "    data_regression = X_train_within.merge(Y_train_within[[\"HHIDPN\",\"tSNE_GHI14_within\"]], on = \"HHIDPN\")\n",
    "    Y_regression = data_regression[\"tSNE_GHI14_within\"]\n",
    "    list_to_drop = [\"HHIDPN\",\"tSNE_GHI14_within\"]\n",
    "    if Lasso_before_within:\n",
    "        list_to_drop = list_to_drop + [col+\"_MEAN\" for col in temporal_variables_within.columns]+[\"INW\"+str(i) for i in range(1,15)]\n",
    "        \n",
    "    X_regression = data_regression.drop(list_to_drop,axis=1)\n",
    "    \n",
    "    return (X_regression, Y_regression)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35d29ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def regression(X_regression,Y_regression):\n",
    "    \n",
    "    modeleReg=LinearRegression()\n",
    "\n",
    "    modeleReg.fit(X_regression,Y_regression) \n",
    "    \n",
    "    return modeleReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "975bbc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Within_estimates(X, Y, HMLasso, Lasso_before_within, method, mu, limit, reduced, print_wave, gen_var):\n",
    "    \n",
    "    if Lasso_before_within:\n",
    "        (selected, names_var, Test) = Lasso_selection(X, Y, HMLasso, method, mu, limit, reduced, print_wave, gen_var)\n",
    "\n",
    "        (X_within, temporal_variables_within) = creation_data_within(selected,Lasso_before_within)\n",
    "        Y_within = creation_outcome_within(Y_train)\n",
    "\n",
    "        (X_regression, Y_regression) = get_X_Y_within(X_within, Y_within, temporal_variables_within, Lasso_before_within)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        (selected, names_var, Test) = Lasso_selection(X, Y, HMLasso, method, mu, limit, reduced, print_wave, gen_var)\n",
    "        \n",
    "        temporal_variables_within = dataset_temporal_variables(selected, False)[0]\n",
    "        #Still Nan values in intemporal variables\n",
    "        selected_2 = selected.fillna(selected.mean())\n",
    "        (X_regression, Y_regression) = get_X_Y_within(selected_2, Y, temporal_variables_within, Lasso_before_within)\n",
    "    \n",
    "    return (regression(X_regression,Y_regression), names_var, X_regression, Y_regression, Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e855fe06",
   "metadata": {},
   "source": [
    "### Optimisation of parameters with validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7d72d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_model (X_train, Y_train, X_valid, Y_valid, HMLasso, Lasso_before_within, method, mu, limit, reduced, coef, print_wave, gen_var):\n",
    "    \n",
    "    (model, names_var, X_regression, Y_regression, Test) = Within_estimates(X_train, Y_train, HMLasso, Lasso_before_within, method, mu, limit, reduced, print_wave, gen_var)\n",
    "    \n",
    "    if Lasso_before_within:\n",
    "        #Selection of columns in the validation set\n",
    "        selected_valid = X_valid[list(names_var)]\n",
    "\n",
    "        (X_valid_within, temporal_variables_within) = creation_data_within(selected_valid, Lasso_before_within)\n",
    "        Y_valid_within = creation_outcome_within(Y_valid)\n",
    "\n",
    "        (X_valid_regression, Y_valid_regression) = get_X_Y_within(X_valid_within, Y_valid_within, temporal_variables_within, Lasso_before_within)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        selected_valid = X_valid[list(names_var)]\n",
    "        #Still Nan values in intemporal variables\n",
    "        selected_valid_2 = selected_valid.fillna(selected_valid.mean())\n",
    "        temporal_variables_within = dataset_temporal_variables(selected_valid, False)[0]\n",
    "        \n",
    "        (X_valid_regression, Y_valid_regression) = get_X_Y_within(selected_valid_2, Y_valid, temporal_variables_within, Lasso_before_within)\n",
    "        \n",
    "    \n",
    "    R_square_train = r_squared(X_regression, Y_regression, model)\n",
    "    R_square_valid = r_squared(X_valid_regression, Y_valid_regression, model)\n",
    "    \n",
    "    intercept = model.intercept_\n",
    "    coefficients = model.coef_\n",
    "    \n",
    "    RMSE_train = RMSE(X_regression, Y_regression, model)\n",
    "    RMSE_valid = RMSE(X_valid_regression, Y_valid_regression, model)\n",
    "\n",
    "    if coef:\n",
    "        summary = {\"HMLasso\" : HMLasso, \"mu\" : mu, \"Lasso_before_within\" : Lasso_before_within, \"R_square_train\" : R_square_train, \"RMSE_train\" : RMSE_train, \"R_square_valid\" : R_square_valid, \"RMSE_valid\" : RMSE_valid, \"variables kept\": len(list(names_var)), \"intercept\" : intercept, \"coefficients\" : coefficients}\n",
    "        return (summary, model, names_var, Test)\n",
    "    \n",
    "    else:\n",
    "        summary = {\"HMLasso\" : HMLasso, \"mu\" : mu, \"Lasso_before_within\" : Lasso_before_within, \"R_square_train\" : R_square_train, \"RMSE_train\" : RMSE_train, \"R_square_valid\" : R_square_valid, \"RMSE_valid\" : RMSE_valid, \"variables kept\": len(list(names_var))}\n",
    "        return (summary, model, names_var, Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ce8899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def r_squared(X, Y, model):\n",
    "    Y_predict = model.predict(X)\n",
    "    \n",
    "    r2 = r2_score(Y, Y_predict)\n",
    "    \n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c23e6e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def RMSE(X, Y, model):\n",
    "    Y_predict = model.predict(X)\n",
    "    \n",
    "    MSE = mean_squared_error(Y, Y_predict)\n",
    "    \n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3633f276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiples_models(X_train, Y_train, X_valid, Y_valid, list_mu, HMLasso, Lasso_before_within, method, limit, reduced, print_wave, gen_var):\n",
    "    \n",
    "    Frame = pd.DataFrame(columns = [\"HMLasso\", \"mu\", \"Lasso_before_within\", \"R_square_train\", \"RMSE_train\", \"R_square_valid\", \"RMSE_valid\", \"variables kept\"])\n",
    "    list_model = []\n",
    "    list_var = []\n",
    "    \n",
    "    for mu in list_mu:\n",
    "        (summary_ML, model, names_var, Test) = summary_model(X_train, Y_train, X_valid, Y_valid, HMLasso, Lasso_before_within, method, mu, limit, reduced, coef=False, print_wave=print_wave, gen_var=gen_var)\n",
    "        Frame = Frame.append(summary_ML, ignore_index=True)\n",
    "        list_model.append(model)\n",
    "        list_var.append(names_var)\n",
    "        \n",
    "    return (Frame, list_model, list_var,Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4647ddda",
   "metadata": {},
   "source": [
    "### Application on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4da181e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model (X_test, Y_test, model, names_var, Lasso_before_within):\n",
    "    \n",
    "    if Lasso_before_within:\n",
    "        #Selection of columns in the validation set\n",
    "        selected_test = X_test[list(names_var)]\n",
    "\n",
    "        (X_test_within, temporal_variables_within) = creation_data_within(selected_test, Lasso_before_within)\n",
    "        Y_test_within = creation_outcome_within(Y_test)\n",
    "\n",
    "        (X_test_regression, Y_test_regression) = get_X_Y_within(X_test_within, Y_test_within, temporal_variables_within, Lasso_before_within)\n",
    "    \n",
    "    else:\n",
    "        selected_test = X_test[list(names_var)]\n",
    "        temporal_variables_within = dataset_temporal_variables(selected_test, False)[0]\n",
    "        #Still Nan values in intemporal variables\n",
    "        selected_test_2 = selected_test.fillna(selected_test.mean())\n",
    "        (X_test_regression, Y_test_regression) = get_X_Y_within(selected_test_2, Y_test, temporal_variables_within, Lasso_before_within)\n",
    "    \n",
    "    R_square_test = model.score(X_test_regression,Y_test_regression, sample_weight=None)\n",
    "    \n",
    "    RMSE_test = RMSE(X_test_regression, Y_test_regression, model)\n",
    "    \n",
    "    return {\"R_square_test\" : R_square_test, \"RMSE_test\" : RMSE_test}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962bd663",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32a14a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mu = [0.01100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e960571",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso selection, mu = 0.011\n",
      "wave 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\1943930034.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_train1.dropna(axis =0, inplace =True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables kept : 2\n",
      "        Wave_1\n",
      "0     0.001137\n",
      "1    -0.006983\n",
      "2    -0.005023\n",
      "3    -0.000107\n",
      "4    -0.003993\n",
      "...        ...\n",
      "2711 -0.000920\n",
      "2712  0.013195\n",
      "2713 -0.005254\n",
      "2714 -0.014189\n",
      "2715  0.019516\n",
      "\n",
      "[2716 rows x 1 columns]\n",
      "wave 2\n",
      "Variables kept : 3\n",
      "wave 3\n",
      "Variables kept : 3\n",
      "wave 4\n",
      "Variables kept : 5\n",
      "wave 5\n",
      "Variables kept : 5\n",
      "wave 6\n",
      "Variables kept : 5\n",
      "wave 7\n",
      "Variables kept : 6\n",
      "wave 8\n",
      "Variables kept : 7\n",
      "wave 9\n",
      "Variables kept : 7\n",
      "wave 10\n",
      "Variables kept : 7\n",
      "wave 11\n",
      "Variables kept : 7\n",
      "wave 12\n",
      "Variables kept : 9\n",
      "wave 13\n",
      "Variables kept : 9\n",
      "wave 14\n",
      "Variables kept : 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kilian\\anaconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_1.loc[wave_1[\"INW1\"] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_1.loc[wave_1[\"INW1\"] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\2199017923.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wave_i.loc[wave_i[\"INWw\".replace('w', str(i))] == 0] = np.nan\n",
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_10700\\1104294669.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Frame = Frame.append(summary_ML, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "(Frame_test, list_model_test, list_var_test, Test) = multiples_models(X_train, Y_train, X_valid, Y_valid, list_mu, HMLasso =False, Lasso_before_within =True, method =\"mean\", limit= -14, reduced =False, print_wave =True, gen_var =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0832ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[51,\n",
       " 102,\n",
       " 153,\n",
       " 204,\n",
       " 255,\n",
       " 306,\n",
       " 357,\n",
       " 408,\n",
       " 459,\n",
       " 510,\n",
       " 561,\n",
       " 612,\n",
       " 663,\n",
       " 714,\n",
       " 58,\n",
       " 116,\n",
       " 174,\n",
       " 232,\n",
       " 290,\n",
       " 348,\n",
       " 406,\n",
       " 464,\n",
       " 522,\n",
       " 580,\n",
       " 638,\n",
       " 696,\n",
       " 754,\n",
       " 812,\n",
       " 35,\n",
       " 70,\n",
       " 105,\n",
       " 140,\n",
       " 175,\n",
       " 210,\n",
       " 245,\n",
       " 280,\n",
       " 315,\n",
       " 350,\n",
       " 385,\n",
       " 420,\n",
       " 455,\n",
       " 490,\n",
       " 28,\n",
       " 56,\n",
       " 84,\n",
       " 112,\n",
       " 140,\n",
       " 168,\n",
       " 196,\n",
       " 224,\n",
       " 252,\n",
       " 280,\n",
       " 308,\n",
       " 336,\n",
       " 364,\n",
       " 392,\n",
       " 26,\n",
       " 52,\n",
       " 78,\n",
       " 104,\n",
       " 130,\n",
       " 156,\n",
       " 182,\n",
       " 208,\n",
       " 234,\n",
       " 260,\n",
       " 286,\n",
       " 312,\n",
       " 338,\n",
       " 364,\n",
       " 34,\n",
       " 68,\n",
       " 102,\n",
       " 136,\n",
       " 170,\n",
       " 204,\n",
       " 238,\n",
       " 272,\n",
       " 306,\n",
       " 340,\n",
       " 374,\n",
       " 408,\n",
       " 442,\n",
       " 476,\n",
       " 32,\n",
       " 64,\n",
       " 96,\n",
       " 128,\n",
       " 160,\n",
       " 192,\n",
       " 224,\n",
       " 256,\n",
       " 288,\n",
       " 320,\n",
       " 352,\n",
       " 384,\n",
       " 416,\n",
       " 448,\n",
       " 23,\n",
       " 46,\n",
       " 69,\n",
       " 92,\n",
       " 115,\n",
       " 138,\n",
       " 161,\n",
       " 184,\n",
       " 207,\n",
       " 230,\n",
       " 253,\n",
       " 276,\n",
       " 299,\n",
       " 322,\n",
       " 18,\n",
       " 36,\n",
       " 54,\n",
       " 72,\n",
       " 90,\n",
       " 108,\n",
       " 126,\n",
       " 144,\n",
       " 162,\n",
       " 180,\n",
       " 198,\n",
       " 216,\n",
       " 234,\n",
       " 252,\n",
       " 29,\n",
       " 58,\n",
       " 87,\n",
       " 116,\n",
       " 145,\n",
       " 174,\n",
       " 203,\n",
       " 232,\n",
       " 261,\n",
       " 290,\n",
       " 319,\n",
       " 348,\n",
       " 377,\n",
       " 406,\n",
       " 26,\n",
       " 52,\n",
       " 78,\n",
       " 104,\n",
       " 130,\n",
       " 156,\n",
       " 182,\n",
       " 208,\n",
       " 234,\n",
       " 260,\n",
       " 286,\n",
       " 312,\n",
       " 338,\n",
       " 364,\n",
       " 24,\n",
       " 48,\n",
       " 72,\n",
       " 96,\n",
       " 120,\n",
       " 144,\n",
       " 168,\n",
       " 192,\n",
       " 216,\n",
       " 240,\n",
       " 264,\n",
       " 288,\n",
       " 312,\n",
       " 336,\n",
       " 64,\n",
       " 128,\n",
       " 192,\n",
       " 256,\n",
       " 320,\n",
       " 384,\n",
       " 448,\n",
       " 512,\n",
       " 576,\n",
       " 640,\n",
       " 704,\n",
       " 768,\n",
       " 832,\n",
       " 896,\n",
       " 35,\n",
       " 70,\n",
       " 105,\n",
       " 140,\n",
       " 175,\n",
       " 210,\n",
       " 245,\n",
       " 280,\n",
       " 315,\n",
       " 350,\n",
       " 385,\n",
       " 420,\n",
       " 455,\n",
       " 490]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_p = []\n",
    "for x in Test:\n",
    "    liste_p.append(len(x[x[\"p_value\"]>= 0.95]))\n",
    "liste_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cf0184fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Test[0][\"p_value\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bac54bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HMLasso</th>\n",
       "      <th>mu</th>\n",
       "      <th>R_square_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>R_square_valid</th>\n",
       "      <th>RMSE_valid</th>\n",
       "      <th>variables kept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.01080</td>\n",
       "      <td>0.093994</td>\n",
       "      <td>1283.853333</td>\n",
       "      <td>0.082117</td>\n",
       "      <td>1310.533455</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>0.01084</td>\n",
       "      <td>0.093247</td>\n",
       "      <td>1284.911427</td>\n",
       "      <td>0.081866</td>\n",
       "      <td>1310.890997</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>0.01088</td>\n",
       "      <td>0.093199</td>\n",
       "      <td>1284.979462</td>\n",
       "      <td>0.082063</td>\n",
       "      <td>1310.609390</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0.01092</td>\n",
       "      <td>0.093148</td>\n",
       "      <td>1285.051891</td>\n",
       "      <td>0.082387</td>\n",
       "      <td>1310.147937</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>0.01096</td>\n",
       "      <td>0.093142</td>\n",
       "      <td>1285.060002</td>\n",
       "      <td>0.082103</td>\n",
       "      <td>1310.553125</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>0.01100</td>\n",
       "      <td>0.092702</td>\n",
       "      <td>1285.684546</td>\n",
       "      <td>0.082827</td>\n",
       "      <td>1309.518518</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>0.01104</td>\n",
       "      <td>0.092697</td>\n",
       "      <td>1285.691428</td>\n",
       "      <td>0.082741</td>\n",
       "      <td>1309.642447</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>0.01108</td>\n",
       "      <td>0.092466</td>\n",
       "      <td>1286.018068</td>\n",
       "      <td>0.080824</td>\n",
       "      <td>1312.378395</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>0.01112</td>\n",
       "      <td>0.092416</td>\n",
       "      <td>1286.090082</td>\n",
       "      <td>0.080732</td>\n",
       "      <td>1312.509812</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>0.01116</td>\n",
       "      <td>0.091695</td>\n",
       "      <td>1287.111061</td>\n",
       "      <td>0.078579</td>\n",
       "      <td>1315.584714</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>0.01120</td>\n",
       "      <td>0.091695</td>\n",
       "      <td>1287.111061</td>\n",
       "      <td>0.078579</td>\n",
       "      <td>1315.584714</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>0.01980</td>\n",
       "      <td>0.075657</td>\n",
       "      <td>1309.837867</td>\n",
       "      <td>0.061375</td>\n",
       "      <td>1340.147657</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>0.01984</td>\n",
       "      <td>0.075657</td>\n",
       "      <td>1309.837885</td>\n",
       "      <td>0.083232</td>\n",
       "      <td>1308.940867</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "      <td>0.01988</td>\n",
       "      <td>0.075657</td>\n",
       "      <td>1309.837867</td>\n",
       "      <td>0.083241</td>\n",
       "      <td>1308.928035</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>0.01992</td>\n",
       "      <td>0.075657</td>\n",
       "      <td>1309.837885</td>\n",
       "      <td>0.083232</td>\n",
       "      <td>1308.940867</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>0.01996</td>\n",
       "      <td>0.075657</td>\n",
       "      <td>1309.837885</td>\n",
       "      <td>0.083232</td>\n",
       "      <td>1308.940867</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>0.075657</td>\n",
       "      <td>1309.837885</td>\n",
       "      <td>0.083232</td>\n",
       "      <td>1308.940867</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>0.02004</td>\n",
       "      <td>0.075657</td>\n",
       "      <td>1309.837885</td>\n",
       "      <td>0.083232</td>\n",
       "      <td>1308.940867</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>False</td>\n",
       "      <td>0.02008</td>\n",
       "      <td>0.075657</td>\n",
       "      <td>1309.837885</td>\n",
       "      <td>0.083232</td>\n",
       "      <td>1308.940867</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "      <td>0.02012</td>\n",
       "      <td>0.074983</td>\n",
       "      <td>1310.793512</td>\n",
       "      <td>0.083015</td>\n",
       "      <td>1309.251435</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>False</td>\n",
       "      <td>0.02016</td>\n",
       "      <td>0.074983</td>\n",
       "      <td>1310.793512</td>\n",
       "      <td>0.083015</td>\n",
       "      <td>1309.251435</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>False</td>\n",
       "      <td>0.02020</td>\n",
       "      <td>0.074983</td>\n",
       "      <td>1310.793513</td>\n",
       "      <td>0.083014</td>\n",
       "      <td>1309.252849</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HMLasso       mu  R_square_train   RMSE_train  R_square_valid   RMSE_valid  \\\n",
       "0    False  0.01080        0.093994  1283.853333        0.082117  1310.533455   \n",
       "1    False  0.01084        0.093247  1284.911427        0.081866  1310.890997   \n",
       "2    False  0.01088        0.093199  1284.979462        0.082063  1310.609390   \n",
       "3    False  0.01092        0.093148  1285.051891        0.082387  1310.147937   \n",
       "4    False  0.01096        0.093142  1285.060002        0.082103  1310.553125   \n",
       "5    False  0.01100        0.092702  1285.684546        0.082827  1309.518518   \n",
       "6    False  0.01104        0.092697  1285.691428        0.082741  1309.642447   \n",
       "7    False  0.01108        0.092466  1286.018068        0.080824  1312.378395   \n",
       "8    False  0.01112        0.092416  1286.090082        0.080732  1312.509812   \n",
       "9    False  0.01116        0.091695  1287.111061        0.078579  1315.584714   \n",
       "10   False  0.01120        0.091695  1287.111061        0.078579  1315.584714   \n",
       "11   False  0.01980        0.075657  1309.837867        0.061375  1340.147657   \n",
       "12   False  0.01984        0.075657  1309.837885        0.083232  1308.940867   \n",
       "13   False  0.01988        0.075657  1309.837867        0.083241  1308.928035   \n",
       "14   False  0.01992        0.075657  1309.837885        0.083232  1308.940867   \n",
       "15   False  0.01996        0.075657  1309.837885        0.083232  1308.940867   \n",
       "16   False  0.02000        0.075657  1309.837885        0.083232  1308.940867   \n",
       "17   False  0.02004        0.075657  1309.837885        0.083232  1308.940867   \n",
       "18   False  0.02008        0.075657  1309.837885        0.083232  1308.940867   \n",
       "19   False  0.02012        0.074983  1310.793512        0.083015  1309.251435   \n",
       "20   False  0.02016        0.074983  1310.793512        0.083015  1309.251435   \n",
       "21   False  0.02020        0.074983  1310.793513        0.083014  1309.252849   \n",
       "\n",
       "   variables kept  \n",
       "0             243  \n",
       "1             241  \n",
       "2             240  \n",
       "3             239  \n",
       "4             238  \n",
       "5             235  \n",
       "6             234  \n",
       "7             232  \n",
       "8             231  \n",
       "9             229  \n",
       "10            229  \n",
       "11            118  \n",
       "12            117  \n",
       "13            118  \n",
       "14            117  \n",
       "15            117  \n",
       "16            117  \n",
       "17            117  \n",
       "18            117  \n",
       "19            116  \n",
       "20            116  \n",
       "21            117  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Frame_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7d0a19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"train\")\n",
    "(X_within_train, temporal_variables_within) = creation_data_within(X_train, Lasso_before_within = False)\n",
    "Y_within_train = creation_outcome_within(Y_train)\n",
    "        \n",
    "#Remove column containing the temporal mean\n",
    "list_to_drop = [col+\"_MEAN\" for col in temporal_variables_within.columns]+[\"INW\"+str(i) for i in range(1,15)]\n",
    "X_within_train = X_within_train.drop(list_to_drop,axis=1)\n",
    "list_to_keep = [f\"tSNE_GHI{w}_within\" for w in range(1,15)]+[\"HHIDPN\"]\n",
    "Y_within_train = Y_within_train[list_to_keep]\n",
    "\n",
    "#Problem with \"INWw\" columns\n",
    "X_within_train = X_within_train.merge(X_train, on=\"HHIDPN\")\n",
    "\n",
    "\n",
    "print(\"valid\")\n",
    "(X_within_valid, temporal_variables_within) = creation_data_within(X_valid, Lasso_before_within = False)\n",
    "Y_within_valid = creation_outcome_within(Y_valid)\n",
    "        \n",
    "#Remove column containing the temporal mean\n",
    "list_to_drop = [col+\"_MEAN\" for col in temporal_variables_within.columns]+[\"INW\"+str(i) for i in range(1,15)]\n",
    "X_within_valid = X_within_valid.drop(list_to_drop,axis=1)\n",
    "list_to_keep = [f\"tSNE_GHI{w}_within\" for w in range(1,15)]+[\"HHIDPN\"]\n",
    "Y_within_valid = Y_within_valid[list_to_keep]\n",
    "  \n",
    "#Problem with \"INWw\" columns\n",
    "X_within_valid = X_within_valid.merge(X_valid, on=\"HHIDPN\")\n",
    "    \n",
    "print(\"test\")\n",
    "(X_within_test, temporal_variables_within) = creation_data_within(X_test, Lasso_before_within = False)\n",
    "Y_within_test = creation_outcome_within(Y_test)\n",
    "        \n",
    "#Remove column containing the temporal mean\n",
    "list_to_drop = [col+\"_MEAN\" for col in temporal_variables_within.columns]+[\"INW\"+str(i) for i in range(1,15)]\n",
    "X_within_test = X_within_test.drop(list_to_drop,axis=1)\n",
    "list_to_keep = [f\"tSNE_GHI{w}_within\" for w in range(1,15)]+[\"HHIDPN\"]\n",
    "Y_within_test = Y_within_test[list_to_keep]\n",
    "\n",
    "#Problem with \"INWw\" columns\n",
    "X_within_test = X_within_test.merge(X_test, on=\"HHIDPN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33328c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_within_train.to_csv('X_within_train.csv',sep = ',', index=False)\n",
    "Y_within_train.to_csv('Y_within_train.csv',sep = ',', index=False)\n",
    "X_within_valid.to_csv('X_within_valid.csv',sep = ',', index=False)\n",
    "Y_within_valid.to_csv('Y_within_valid.csv',sep = ',', index=False)\n",
    "X_within_test.to_csv('X_within_test.csv',sep = ',', index=False)\n",
    "Y_within_test.to_csv('Y_within_test.csv',sep = ',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4498741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_within_train = pd.read_csv('X_within_train.csv')\n",
    "Y_within_train = pd.read_csv('Y_within_train.csv')\n",
    "X_within_valid = pd.read_csv('X_within_valid.csv')\n",
    "Y_within_valid = pd.read_csv('Y_within_valid.csv')\n",
    "X_within_test = pd.read_csv('X_within_test.csv')\n",
    "Y_within_test = pd.read_csv('Y_within_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
