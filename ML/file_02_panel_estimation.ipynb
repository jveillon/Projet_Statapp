{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c0307ef",
   "metadata": {},
   "source": [
    "Import of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "747ca7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler # To standardize the data\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fbb11d",
   "metadata": {},
   "source": [
    "Import of the HMLasso function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e07cd446",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adapt the path \"C:/Users/Kilian/Desktop/ENSAE/STATAPP\" to run the cell\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, 'C:/Users/Kilian/Desktop/ENSAE/STATAPP/Projet_Statapp/pretreatment')\n",
    "\n",
    "import file_04_HMLasso as hml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf72f6ac",
   "metadata": {},
   "source": [
    "## Data downloading and separation of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ca111d",
   "metadata": {},
   "source": [
    "Dataset containing the types of each column from data_03.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f16325af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HHIDPN</td>\n",
       "      <td>Cont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HHID</td>\n",
       "      <td>Char</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PN</td>\n",
       "      <td>Char</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  Type\n",
       "0  HHIDPN  Cont\n",
       "1    HHID  Char\n",
       "2      PN  Char"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_types = pd.read_csv(\"data_03_columns_types.csv\", index_col=0)\n",
    "columns_types.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfbe86a",
   "metadata": {},
   "source": [
    "Downloading the data with social and genetic variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "015166c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kilian\\AppData\\Local\\Temp\\ipykernel_6808\\3952530018.py:1: DtypeWarning: Columns (2684) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"data_03.csv\")\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data_03.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aec591",
   "metadata": {},
   "source": [
    "The column \"genetic_Section_A_or_E\" have mixed types, so we change its format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "965a817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary = np.where(data['genetic_Section_A_or_E'] == 'E', 1, np.where(data['genetic_Section_A_or_E'] == 'A', 0, np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02f5d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"genetic_Section_A_or_E\"] = temporary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6b4e72",
   "metadata": {},
   "source": [
    "Now we add the health index created by t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f6a30ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tSNE_GHI = pd.read_csv(\"data_tSNE_GHI.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379fa4f3",
   "metadata": {},
   "source": [
    "We merge the t-SNE health index to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c121e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(tSNE_GHI, how ='left', on ='HHIDPN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf31a8d",
   "metadata": {},
   "source": [
    "The final outcome to predict is tSNE_GHI14, so we only keep individuals who were interviewed during the last wave (14th wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3ebbb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bis = data[data['tSNE_GHI14'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7ead7a",
   "metadata": {},
   "source": [
    "Number of individuals present in every waves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f7abd54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3396"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tSNE_GHI[~tSNE_GHI.isnull().any(axis=1)].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed04aaf5",
   "metadata": {},
   "source": [
    "We select the outcome tSNE_GHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39aa86f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data_bis[[\"tSNE_GHI\" + str(i) for i in range (1,15)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c563e1a",
   "metadata": {},
   "source": [
    "We drop the previous health index GHIw from the data, which won't be used as outcome.\n",
    "(list_columns_GHI contains the names of GHIw columns).\n",
    "\n",
    "We drop the outcome to create the matrix X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "559e8cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_bis.drop([\"GHI\" + str(i) for i in range (1,15)], axis = 1)\n",
    "X.drop([\"tSNE_GHI\" + str(i) for i in range (1,15)], axis = 1, inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f228abcf",
   "metadata": {},
   "source": [
    "Now we split the dataset into training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bebb3e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=18)\n",
    "X_test, X_valid, Y_test, Y_valid = train_test_split(X_test, Y_test, test_size=0.5, random_state = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be7c060",
   "metadata": {},
   "source": [
    "Smaller sets while coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51094fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_test, nb_train, nb_valid = len(X_test.index)//10, len(X_train.index)//10, len(X_valid.index)//10\n",
    "X_test, Y_test = X_test.iloc[:nb_test], Y_test.iloc[:nb_test]\n",
    "X_train, Y_train = X_train.iloc[:nb_train], Y_train.iloc[:nb_train]\n",
    "X_valid, Y_valid = X_valid.iloc[:nb_valid], Y_valid.iloc[:nb_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4641a491",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(\"X_test.csv\", index=False)\n",
    "Y_test.to_csv(\"Y_test.csv\", index=False)\n",
    "X_train.to_csv(\"X_train.csv\", index=False)\n",
    "Y_train.to_csv(\"Y_train.csv\", index=False)\n",
    "X_valid.to_csv(\"X_valid.csv\", index=False)\n",
    "Y_valid.to_csv(\"Y_valid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6df53f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If needed\n",
    "X_test = pd.read_csv(\"X_test.csv\", index_col=0)\n",
    "Y_test = pd.read_csv(\"Y_test.csv\", index_col=0)\n",
    "X_train = pd.read_csv(\"X_train.csv\", index_col=0)\n",
    "Y_train = pd.read_csv(\"Y_train.csv\", index_col=0)\n",
    "X_valid = pd.read_csv(\"X_valid.csv\", index_col=0)\n",
    "Y_valid = pd.read_csv(\"Y_valid.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ddedcf",
   "metadata": {},
   "source": [
    "## Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cde8436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The objective here is to make a dataset where we observe if each variable exists at each wave\n",
    "temporal_variables = {}\n",
    "waves_columns = [col for col in X_train.columns if \"genetic_\" not in col and col[1] in \"123456789\"]\n",
    "for col in waves_columns:\n",
    "  char = col[0] # R or H\n",
    "  if col[2] in \"01234\":\n",
    "    wave = col[1:3]\n",
    "    suffix = col[3:]\n",
    "  else:\n",
    "    wave = col[1]\n",
    "    suffix = col[2:]\n",
    "  variable = char + 'w' + suffix\n",
    "  \n",
    "  if variable not in temporal_variables.keys():\n",
    "    temporal_variables[variable] = np.zeros((14), dtype=bool)\n",
    "  \n",
    "  temporal_variables[variable][int(wave)-1] = True\n",
    "\n",
    "temporal_variables = pd.DataFrame(temporal_variables)\n",
    "\n",
    "# We manually add \"GHIw\":\n",
    "temporal_variables[\"tSNE_GHIw\"] = np.ones((14), dtype=bool)\n",
    "waves_columns += [f\"t_SNE_GHI{w}\" for w in range(1,15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8869d3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeless data\n",
    "non_waves_columns = [col for col in X_train.columns if col not in waves_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af029937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We put the explaining variables by wave in a list of dataset\n",
    "# Intemporal variables are put in each one of them\n",
    "liste = []    # len = 14 \n",
    "for i in range(14):\n",
    "    columns_wave_i = [col.replace('w', str(i+1)) for col in temporal_variables.T[i].index[temporal_variables.T[i]] if col != \"tSNE_GHIw\"]\n",
    "    liste.append(X_train.loc[X_train[\"INW\"+str(i+1)] == 1, columns_wave_i + non_waves_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0d90002",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = liste[0].values #Rajouter var X train en dataframe\n",
    "Y_train1 = Y_train.iloc[:,0]\n",
    "Y_train1.dropna(inplace =True)\n",
    "Y_train1 = Y_train1.values\n",
    "Y_train1 = (Y_train1 - np.mean(Y_train1))/np.std(Y_train1)\n",
    "#Y_train1 = Y_train1\n",
    "#Vérifier meme longueur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4985cd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kilian\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:985: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "C:\\Users\\Kilian\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:990: RuntimeWarning: invalid value encountered in true_divide\n",
      "  T = new_sum / new_sample_count\n",
      "C:\\Users\\Kilian\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:1020: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_unnormalized_variance -= correction ** 2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()#(with_std=False)\n",
    "X_train1 = scaler.fit_transform(X_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e06544",
   "metadata": {},
   "source": [
    "We apply the lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b97c6602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Imputing parameters] Starting...\n",
      "[Imputing parameters] R calculated.\n",
      "[Imputing parameters] rho_pair calculated.\n",
      "[Imputing parameters] S_pair calculated.\n",
      "[Imputing parameters] Parameters imputed.\n",
      "[First Problem] Starting...\n",
      "[First Problem] Objective and constraints well-defined.\n",
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.3.1                                    \n",
      "===============================================================================\n",
      "(CVXPY) Apr 22 08:41:47 PM: Your problem has 929296 variables, 1 constraints, and 0 parameters.\n",
      "(CVXPY) Apr 22 08:41:47 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Apr 22 08:41:47 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Apr 22 08:41:47 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Apr 22 08:41:47 PM: Compiling problem (target solver=SCS).\n",
      "(CVXPY) Apr 22 08:41:47 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> SCS\n",
      "(CVXPY) Apr 22 08:41:47 PM: Applying reduction Dcp2Cone\n",
      "(CVXPY) Apr 22 08:41:47 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Apr 22 08:41:48 PM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) Apr 22 08:41:51 PM: Applying reduction SCS\n",
      "(CVXPY) Apr 22 08:41:53 PM: Finished problem compilation (took 6.192e+00 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Apr 22 08:41:53 PM: Invoking solver SCS  to obtain a solution.\n",
      "------------------------------------------------------------------\n",
      "\t       SCS v3.2.3 - Splitting Conic Solver\n",
      "\t(c) Brendan O'Donoghue, Stanford University, 2012\n",
      "------------------------------------------------------------------\n",
      "problem:  variables n: 1394426, constraints m: 1859556\n",
      "cones: \t  z: primal zero / dual free vars: 929296\n",
      "\t  s: psd vars: 930260, ssize: 2\n",
      "settings: eps_abs: 1.0e-05, eps_rel: 1.0e-05, eps_infeas: 1.0e-07\n",
      "\t  alpha: 1.50, scale: 1.00e-01, adaptive_scale: 1\n",
      "\t  max_iters: 100000, normalize: 1, rho_x: 1.00e-06\n",
      "\t  acceleration_lookback: 10, acceleration_interval: 10\n",
      "lin-sys:  sparse-direct-amd-qdldl\n",
      "\t  nnz(A): 2499224, nnz(P): 929296\n",
      "------------------------------------------------------------------\n",
      " iter | pri res | dua res |   gap   |   obj   |  scale  | time (s)\n",
      "------------------------------------------------------------------\n",
      "     0| 9.98e-01  7.43e-01  1.49e+03  9.19e+02  1.00e-01  1.24e+01 \n",
      "   225| 1.82e-05  2.37e-06  1.05e-05  4.46e+00  1.66e-02  2.52e+03 \n",
      "------------------------------------------------------------------\n",
      "status:  solved\n",
      "timings: total: 2.52e+03s = setup: 4.17e+00s + solve: 2.51e+03s\n",
      "\t lin-sys: 3.04e+01s, cones: 2.47e+03s, accel: 2.74e+00s\n",
      "------------------------------------------------------------------\n",
      "objective = 4.464801\n",
      "------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Apr 22 09:23:49 PM: Problem status: optimal\n",
      "(CVXPY) Apr 22 09:23:49 PM: Optimal value: 4.465e+00\n",
      "(CVXPY) Apr 22 09:23:49 PM: Compilation took 6.192e+00 seconds\n",
      "(CVXPY) Apr 22 09:23:49 PM: Solver (including time spent in interface) took 2.516e+03 seconds\n",
      "[First Problem] Problem status: optimal.\n",
      "[First Problem] Problem solved.\n",
      "[Warning] Sigma_opt is not PSD, its minimum eigenvalue is (-3.3480114260289826e-05+0j). Error handled by adding (3.3480114260289826e-05-0j) to each eigenvalue.\n",
      "[Second Problem] Starting...\n",
      "[Second Problem] Objective and constraints well-defined.\n",
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.3.1                                    \n",
      "===============================================================================\n",
      "(CVXPY) Apr 22 09:23:51 PM: Your problem has 964 variables, 0 constraints, and 0 parameters.\n",
      "(CVXPY) Apr 22 09:23:51 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Apr 22 09:23:51 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Apr 22 09:23:51 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Apr 22 09:23:51 PM: Compiling problem (target solver=SCS).\n",
      "(CVXPY) Apr 22 09:23:51 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> SCS\n",
      "(CVXPY) Apr 22 09:23:51 PM: Applying reduction Dcp2Cone\n",
      "(CVXPY) Apr 22 09:23:51 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Apr 22 09:23:51 PM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) Apr 22 09:23:51 PM: Applying reduction SCS\n",
      "(CVXPY) Apr 22 09:23:52 PM: Finished problem compilation (took 8.019e-01 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Apr 22 09:23:52 PM: Invoking solver SCS  to obtain a solution.\n",
      "------------------------------------------------------------------\n",
      "\t       SCS v3.2.3 - Splitting Conic Solver\n",
      "\t(c) Brendan O'Donoghue, Stanford University, 2012\n",
      "------------------------------------------------------------------\n",
      "problem:  variables n: 1928, constraints m: 1928\n",
      "cones: \t  l: linear vars: 1928\n",
      "settings: eps_abs: 1.0e-05, eps_rel: 1.0e-05, eps_infeas: 1.0e-07\n",
      "\t  alpha: 1.50, scale: 1.00e-01, adaptive_scale: 1\n",
      "\t  max_iters: 100000, normalize: 1, rho_x: 1.00e-06\n",
      "\t  acceleration_lookback: 10, acceleration_interval: 10\n",
      "lin-sys:  sparse-direct-amd-qdldl\n",
      "\t  nnz(A): 3856, nnz(P): 444175\n",
      "------------------------------------------------------------------\n",
      " iter | pri res | dua res |   gap   |   obj   |  scale  | time (s)\n",
      "------------------------------------------------------------------\n",
      "     0| 1.41e+03  1.00e+02  1.35e+08 -6.77e+07  1.00e-01  7.44e-01 \n",
      "   125| 1.08e-10  3.83e-13  4.91e-10 -2.45e-10  1.09e+03  1.49e+00 \n",
      "------------------------------------------------------------------\n",
      "status:  solved\n",
      "timings: total: 1.49e+00s = setup: 7.27e-01s + solve: 7.66e-01s\n",
      "\t lin-sys: 4.21e-01s, cones: 3.30e-03s, accel: 6.66e-04s\n",
      "------------------------------------------------------------------\n",
      "objective = -0.000000\n",
      "------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Apr 22 09:23:53 PM: Problem status: optimal\n",
      "(CVXPY) Apr 22 09:23:53 PM: Optimal value: 1.013e-06\n",
      "(CVXPY) Apr 22 09:23:53 PM: Compilation took 8.019e-01 seconds\n",
      "(CVXPY) Apr 22 09:23:53 PM: Solver (including time spent in interface) took 1.607e+00 seconds\n",
      "[Second Problem] Problem status: optimal.\n",
      "[Second Problem] Problem solved.\n",
      "\n",
      "Model fitted.\n"
     ]
    }
   ],
   "source": [
    "hml.ERRORS_HANDLING = \"ignore\"\n",
    "lasso = hml.HMLasso(mu = 100)\n",
    "lasso.fit(X_train1, Y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56f961c",
   "metadata": {},
   "source": [
    "Seuil à 10e-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e79c398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = lasso.beta_opt.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "87a7bc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.52855022e-11, 1.38769180e-12, 2.32397560e-11, 1.95931350e-13,\n",
       "       3.41285511e-11, 1.59447484e-11, 4.68248118e-12, 3.64647758e-11,\n",
       "       1.52100104e-11, 2.32098795e-11, 2.19761735e-11, 1.02961532e-11,\n",
       "       1.19571041e-11, 1.11891525e-11, 2.99360187e-20, 1.15831705e-11,\n",
       "       1.01215561e-11, 2.90000523e-11, 2.90292116e-11, 2.90150433e-11,\n",
       "       2.88613595e-11, 2.89190709e-11, 2.89190676e-11, 7.25043143e-13,\n",
       "       9.14267115e-12, 9.14267119e-12, 7.84097441e-12, 1.02962399e-11,\n",
       "       1.42615419e-11, 3.80986736e-12, 1.25994177e-11, 1.75995254e-11,\n",
       "       4.15135394e-13, 1.57932072e-12, 5.33661538e-12, 1.04997607e-11,\n",
       "       6.04190647e-13, 7.02717907e-12, 8.93692992e-12, 5.49080284e-12,\n",
       "       1.04228703e-11, 4.00722289e-13, 9.83361003e-12, 5.91300572e-12,\n",
       "       4.52895331e-15, 7.04127218e-12, 2.15491149e-12, 4.47684400e-12,\n",
       "       1.90861701e-12, 4.03732681e-12, 8.53803213e-13, 3.84943668e-12,\n",
       "       1.34205562e-11, 3.66107723e-11, 1.71726927e-11, 1.67110121e-11,\n",
       "       4.55907153e-12, 2.85745776e-11, 3.32254859e-12, 4.90759722e-12,\n",
       "       7.03300006e-12, 2.36331142e-11, 6.59011965e-12, 1.71585756e-12,\n",
       "       1.83828021e-11, 2.02462668e-12, 1.72344897e-11, 2.07870607e-11,\n",
       "       2.55695762e-11, 1.60514591e-11, 1.12330192e-11, 1.15563469e-11,\n",
       "       6.09573544e-12, 2.16583873e-11, 1.61644409e-11, 1.49788932e-11,\n",
       "       1.06834922e-11, 1.85401295e-12, 4.87079670e-12, 1.48986151e-11,\n",
       "       1.49083138e-11, 1.00454814e-11, 2.15902943e-12, 9.83784277e-12,\n",
       "       5.72232276e-12, 2.10998255e-11, 3.67624777e-11, 1.13119223e-11,\n",
       "       3.48280917e-12, 4.23172508e-11, 2.23962942e-11, 2.95628160e-20,\n",
       "       1.07184514e-11, 4.21913333e-11, 1.95316696e-11, 1.98584405e-11,\n",
       "       3.90979377e-11, 3.02796712e-11, 1.40793389e-12, 2.09935752e-12,\n",
       "       1.44025746e-11, 1.98501185e-11, 2.37582204e-11, 2.70765953e-12,\n",
       "       1.40734017e-11, 2.98699756e-11, 6.19269607e-12, 1.50162284e-11,\n",
       "       2.19592108e-11, 3.60643643e-11, 1.12258657e-11, 3.59939385e-12,\n",
       "       2.62409067e-11, 1.22954798e-12, 1.65966960e-11, 1.79562971e-11,\n",
       "       1.99802093e-11, 1.02812694e-11, 2.32306599e-11, 3.33927052e-13,\n",
       "       1.25689391e-11, 2.38215677e-11, 1.44127480e-11, 9.66380829e-12,\n",
       "       1.18818808e-12, 7.85866528e-12, 5.74164140e-12, 2.48112838e-12,\n",
       "       8.95822960e-12, 5.13508315e-12, 7.07272473e-12, 3.07896009e-11,\n",
       "       2.14431037e-11, 6.74585487e-12, 7.58721971e-12, 1.40060851e-11,\n",
       "       1.37597310e-11, 2.03310356e-11, 2.32571920e-11, 6.00947066e-12,\n",
       "       4.39313569e-11, 2.87912632e-11, 4.73620811e-12, 7.39758390e-13,\n",
       "       1.99876520e-11, 9.88204053e-12, 6.30452482e-13, 5.24274247e-12,\n",
       "       2.82625174e-11, 7.01395835e-12, 6.56842116e-12, 2.04395774e-11,\n",
       "       1.08719531e-11, 1.95825368e-11, 3.73322783e-11, 1.11333558e-23,\n",
       "       2.96087951e-20, 3.13313017e-20, 2.93454793e-20, 2.96072369e-20,\n",
       "       2.75793787e-20, 2.93030940e-20, 4.55233983e-12, 1.22192728e-12,\n",
       "       6.19446875e-12, 6.85171564e-12, 2.34548825e-11, 2.56297870e-12,\n",
       "       3.05435536e-11, 4.34782182e-12, 5.41487646e-12, 2.05697758e-11,\n",
       "       9.19981429e-12, 3.63238722e-12, 1.49160708e-11, 7.82372297e-12,\n",
       "       3.08092596e-11, 1.58707677e-11, 7.36599883e-12, 4.60459086e-12,\n",
       "       2.52854846e-11, 3.53999149e-12, 3.49623351e-11, 4.38821129e-12,\n",
       "       2.35141980e-11, 7.36601379e-12, 4.60459088e-12, 1.73971523e-12,\n",
       "       3.20540786e-11, 8.01163848e-13, 3.41285523e-11, 9.86615790e-21,\n",
       "       2.93413149e-20, 3.40199982e-11, 2.97806671e-11, 3.07462003e-11,\n",
       "       2.55577774e-11, 2.15013489e-11, 1.18042758e-24, 1.83940132e-24,\n",
       "       2.96074645e-20, 6.85471769e-25, 1.03409198e-24, 5.69065542e-11,\n",
       "       4.56664269e-11, 2.68265378e-11, 7.69453539e-12, 2.93447262e-20,\n",
       "       1.65752701e-11, 1.63337143e-11, 2.72268214e-12, 3.13401789e-20,\n",
       "       1.65257281e-11, 2.02600058e-11, 4.87227185e-12, 3.13337984e-20,\n",
       "       2.95685366e-20, 7.51820794e-25, 2.93031559e-20, 2.93038149e-20,\n",
       "       1.40060851e-11, 1.99461156e-11, 1.55879795e-12, 4.91181586e-12,\n",
       "       2.75791044e-20, 9.88207437e-12, 4.86039477e-12, 1.01904086e-11,\n",
       "       2.33624106e-25, 2.93026830e-20, 6.30494221e-13, 2.49931451e-12,\n",
       "       4.05046991e-12, 2.93429930e-20, 9.72731056e-25, 5.24273030e-12,\n",
       "       6.26336730e-12, 2.02175725e-13, 2.96387496e-20, 6.77761214e-26,\n",
       "       2.82624744e-11, 2.99053824e-11, 3.11849801e-12, 6.58159800e-24,\n",
       "       2.95687772e-20, 3.16367831e-12, 1.93169340e-12, 1.68189897e-11,\n",
       "       3.53712004e-12, 1.36412492e-11, 5.80216691e-12, 1.63325969e-11,\n",
       "       2.36849378e-14, 6.41492257e-12, 2.67775500e-12, 8.85621360e-12,\n",
       "       1.26631021e-11, 1.72517040e-11, 1.25600224e-11, 3.42831775e-11,\n",
       "       2.02659567e-11, 5.66559570e-12, 1.12054367e-11, 2.47208011e-11,\n",
       "       9.49913431e-12, 2.14431037e-11, 1.18541021e-11, 2.66960233e-11,\n",
       "       6.51017918e-12, 2.96367390e-20, 4.02323112e-12, 1.62703609e-11,\n",
       "       9.08793229e-13, 2.91625301e-11, 1.14413537e-11, 7.58717698e-12,\n",
       "       1.52317813e-11, 5.13688787e-12, 1.53713936e-11, 2.95696991e-20,\n",
       "       1.83074373e-11, 2.47329589e-12, 6.36284019e-12, 1.15884756e-11,\n",
       "       2.68926653e-11, 2.03310923e-11, 1.79822227e-11, 6.04108100e-12,\n",
       "       1.88880737e-12, 5.33895195e-25, 2.10822617e-11, 8.00074899e-13,\n",
       "       3.00702407e-11, 9.13138763e-12, 9.91358184e-12, 5.52619743e-12,\n",
       "       1.06527830e-12, 1.29248945e-11, 6.67078464e-12, 1.24211665e-13,\n",
       "       4.34589399e-11, 3.18585551e-11, 1.50188920e-11, 1.45366303e-11,\n",
       "       4.91181568e-12, 2.70069236e-11, 1.51772005e-11, 2.29764007e-11,\n",
       "       9.14144517e-12, 1.28075982e-11, 4.73620782e-12, 4.58561074e-12,\n",
       "       4.12916341e-12, 7.95515071e-12, 3.13406860e-20, 7.39749975e-13,\n",
       "       3.58316097e-13, 2.04739167e-12, 1.74861871e-12, 2.96067550e-20,\n",
       "       1.85817884e-11, 6.09802003e-13, 3.01774449e-11, 5.76817923e-12,\n",
       "       2.12949732e-12, 4.48480011e-12, 6.74419368e-12, 2.93438882e-20,\n",
       "       1.24728905e-12, 1.45407908e-11, 8.10413220e-12, 1.24655556e-11,\n",
       "       1.59447484e-11, 3.06893184e-12, 1.39144285e-11, 9.10989802e-12,\n",
       "       8.15071711e-13, 1.94816213e-11, 1.35699653e-11, 1.59447060e-11,\n",
       "       9.54113196e-12, 2.12060750e-11, 1.42561603e-11, 8.60957496e-12,\n",
       "       3.42572511e-12, 4.46765221e-12, 2.43598467e-11, 1.59447480e-11,\n",
       "       1.27218405e-11, 5.57044840e-12, 8.41035821e-12, 1.59447485e-11,\n",
       "       9.24291818e-12, 5.44757216e-13, 1.39705891e-11, 1.03987505e-12,\n",
       "       3.31847884e-11, 1.88382793e-11, 2.43598463e-11, 1.59447483e-11,\n",
       "       5.50726403e-12, 5.03171549e-12, 1.81338302e-12, 4.16811762e-12,\n",
       "       8.54649504e-12, 3.01099075e-12, 2.14115654e-11, 1.59447484e-11,\n",
       "       9.57149928e-13, 1.77928900e-11, 5.39770950e-12, 7.77955362e-12,\n",
       "       7.34743417e-12, 1.27960100e-11, 6.31762584e-12, 1.59447063e-11,\n",
       "       7.34610857e-12, 9.49161918e-12, 3.13408617e-20, 1.38114250e-11,\n",
       "       5.45930437e-12, 1.60312298e-11, 1.54738570e-11, 1.59447489e-11,\n",
       "       1.50572116e-11, 4.12703258e-12, 1.45180602e-25, 1.07318822e-11,\n",
       "       3.00020187e-12, 1.28683465e-11, 8.48512702e-12, 1.59447485e-11,\n",
       "       1.25035820e-11, 4.17480234e-12, 8.41559344e-12, 9.85200988e-12,\n",
       "       8.47495669e-12, 1.59447063e-11, 4.83794603e-12, 1.10161560e-11,\n",
       "       8.55797211e-13, 5.75566027e-13, 2.64831388e-26, 1.59447485e-11,\n",
       "       8.13993451e-12, 4.00069798e-12, 5.93210314e-12, 1.59447485e-11,\n",
       "       2.22693346e-11, 8.48518127e-12, 2.59143260e-11, 1.59447486e-11,\n",
       "       7.29466364e-13, 1.90515330e-11, 6.71984952e-12, 1.24200990e-11,\n",
       "       4.19198670e-11, 1.59447201e-11, 6.82441260e-12, 1.90515480e-11,\n",
       "       7.63172702e-12, 1.94917116e-11, 4.19199067e-11, 1.59447484e-11,\n",
       "       2.01975687e-11, 9.66364040e-12, 9.13656877e-12, 1.59447485e-11,\n",
       "       2.22250889e-11, 3.57228750e-12, 3.28630164e-11, 1.59447486e-11,\n",
       "       1.12435367e-11, 2.11101656e-11, 1.24655557e-11, 1.59447067e-11,\n",
       "       9.59288498e-12, 2.00696822e-11, 1.24655557e-11, 1.59447487e-11,\n",
       "       8.72300176e-12, 6.33372719e-12, 2.43598466e-11, 1.59447063e-11,\n",
       "       3.17913177e-11, 3.24165087e-11, 2.43598333e-11, 1.59447063e-11,\n",
       "       2.55694791e-11, 1.66593643e-26, 2.52275609e-11, 2.43598487e-11,\n",
       "       1.59447486e-11, 1.55105687e-11, 3.85827166e-26, 1.61701184e-11,\n",
       "       2.43598332e-11, 1.59447066e-11, 7.31196634e-12, 4.53552224e-12,\n",
       "       2.43598332e-11, 1.59447064e-11, 2.21972604e-11, 1.08803825e-11,\n",
       "       1.73042174e-11, 2.43598355e-11, 1.59447485e-11, 1.73077519e-12,\n",
       "       1.91152928e-26, 4.87848490e-12, 2.43598467e-11, 1.59447486e-11,\n",
       "       2.40963290e-12, 5.68192512e-13, 1.20300671e-11, 1.59447488e-11,\n",
       "       1.20960008e-11, 1.25196257e-13, 2.68287510e-11, 1.59447484e-11,\n",
       "       5.24717150e-12, 3.48619748e-11, 3.21364236e-11, 1.59447486e-11,\n",
       "       3.24164146e-11, 4.05828856e-26, 2.39468305e-11, 1.21878465e-26,\n",
       "       2.21506391e-11, 2.38005469e-26, 5.02493415e-26, 2.27476784e-11,\n",
       "       1.02069795e-11, 1.48531467e-11, 6.90547938e-13, 3.47572020e-11,\n",
       "       1.48977944e-11, 3.08978180e-11, 8.96280522e-12, 6.91793665e-12,\n",
       "       2.31239207e-12, 9.98829501e-12, 1.76053189e-11, 1.85170956e-12,\n",
       "       9.54865445e-12, 7.16963367e-12, 1.89038089e-11, 5.39786297e-12,\n",
       "       3.63068454e-12, 1.49839663e-11, 5.17477049e-11, 8.08269410e-11,\n",
       "       3.58855196e-11, 7.27597305e-12, 8.65729939e-12, 2.80313383e-11,\n",
       "       2.54149857e-11, 4.05052979e-12, 3.66303882e-12, 3.53042645e-11,\n",
       "       8.05337249e-12, 8.65729942e-12, 2.61633693e-11, 2.54149684e-11,\n",
       "       4.05050859e-12, 3.66298176e-12, 6.17450214e-13, 9.07198447e-12,\n",
       "       1.37253753e-11, 1.74904755e-11, 8.65731328e-12, 5.03213414e-27,\n",
       "       2.20799938e-11, 7.05161537e-12, 1.74905033e-11, 8.65729934e-12,\n",
       "       5.83169479e-27, 2.20799940e-11, 7.05155825e-12, 1.21563110e-11,\n",
       "       2.77725933e-12, 1.24432150e-11, 7.49703818e-13, 6.79905191e-12,\n",
       "       1.13645907e-11, 1.23428985e-11, 8.97769793e-12, 1.13447758e-11,\n",
       "       8.97747783e-12, 2.75238331e-11, 1.24849967e-11, 8.15543179e-12,\n",
       "       1.65583644e-12, 2.04718221e-11, 1.93585376e-12, 6.82353692e-14,\n",
       "       1.20485606e-13, 5.00275626e-12, 1.44863097e-11, 1.07571346e-10,\n",
       "       1.84411194e-27, 1.07571333e-10, 3.77607585e-13, 1.36568118e-11,\n",
       "       1.52614816e-11, 1.19632392e-12, 1.63601709e-12, 3.45537644e-12,\n",
       "       5.88703346e-12, 4.34708357e-11, 1.03442370e-11, 7.25124869e-12,\n",
       "       1.45174010e-11, 6.13648089e-14, 9.69659805e-12, 1.75585313e-12,\n",
       "       7.63319734e-12, 4.31053924e-12, 4.20787015e-12, 1.37030487e-11,\n",
       "       5.20125086e-13, 6.20954563e-12, 1.21762134e-11, 1.42881097e-12,\n",
       "       1.49580303e-11, 6.30236819e-12, 3.84456354e-12, 2.76520452e-12,\n",
       "       1.26102240e-11, 6.70406255e-12, 1.41952360e-12, 1.38205811e-11,\n",
       "       7.54838192e-12, 1.99198611e-11, 1.98378440e-11, 1.44258553e-11,\n",
       "       1.15570295e-33, 2.64316274e-12, 4.48173983e-12, 5.62004351e-12,\n",
       "       3.55409514e-12, 1.44374853e-33, 1.20077067e-33, 1.62952362e-11,\n",
       "       2.00514542e-11, 5.19099297e-12, 1.59447485e-11, 9.33197547e-12,\n",
       "       7.65121754e-12, 3.17848519e-12, 2.60694956e-12, 7.40049807e-12,\n",
       "       2.77820878e-12, 1.35694580e-11, 4.19412170e-12, 1.24302655e-11,\n",
       "       1.82050597e-11, 2.47269096e-11, 7.09518381e-12, 2.72589894e-12,\n",
       "       1.66221557e-12, 4.62457660e-12, 2.66450807e-12, 5.97402679e-12,\n",
       "       1.44974685e-11, 3.99633462e-12, 2.73013211e-11, 1.63973566e-11,\n",
       "       1.93580761e-11, 2.99380530e-12, 5.11008491e-12, 1.74861850e-12,\n",
       "       5.58843103e-34, 1.02961819e-11, 1.35535174e-35, 1.50968995e-11,\n",
       "       9.08959927e-12, 7.76175348e-12, 5.50409402e-12, 4.13578435e-12,\n",
       "       1.97916121e-12, 1.09076504e-11, 7.97564847e-12, 6.50427147e-12,\n",
       "       7.84886023e-12, 1.48288351e-11, 1.06067319e-11, 9.01609307e-35,\n",
       "       2.90439072e-12, 1.35885640e-11, 7.84096762e-12, 1.02962399e-11,\n",
       "       3.57901180e-11, 2.16836656e-11, 8.49129381e-12, 2.91014228e-11,\n",
       "       2.95890542e-11, 2.90834675e-34, 4.48968793e-35, 3.40652877e-34,\n",
       "       3.82947114e-34, 4.38544463e-36, 1.81728833e-34, 6.47045644e-36,\n",
       "       1.88055132e-11, 1.28427711e-11, 1.19974167e-11, 9.74840673e-34,\n",
       "       1.62539233e-11, 1.02961134e-11, 1.35885271e-11, 1.63889342e-34,\n",
       "       2.07371538e-11, 2.71158602e-34, 5.01464423e-34, 3.67248513e-34,\n",
       "       1.81712540e-34, 1.19824553e-34, 7.46482265e-35, 3.69209639e-35,\n",
       "       1.80043927e-11, 2.70476734e-11, 2.70622980e-11, 1.11305956e-11,\n",
       "       8.79922004e-35, 2.66370376e-34, 2.17266058e-34, 4.95490482e-35,\n",
       "       1.09683369e-11, 1.67804327e-11, 5.68914868e-13, 6.72177334e-12,\n",
       "       2.08302588e-11, 1.90012619e-11, 1.03806412e-11, 4.46634239e-12,\n",
       "       1.90850978e-11, 3.68180093e-12, 1.16230686e-11, 1.62995743e-11,\n",
       "       1.24681001e-11, 1.64262552e-12, 3.00522832e-11, 1.44205413e-11,\n",
       "       1.15925193e-11, 1.46300551e-11, 1.46391753e-11, 4.47730515e-12,\n",
       "       1.50703862e-11, 1.03670953e-11, 1.05347770e-11, 1.50480834e-11,\n",
       "       1.85558473e-11, 1.43913018e-13, 2.82248567e-12, 2.71638918e-12,\n",
       "       1.26365544e-12, 2.40504557e-11, 4.42768182e-12, 1.34299741e-12,\n",
       "       6.67514354e-12, 6.98636326e-13, 1.78450927e-11, 2.15062750e-11,\n",
       "       2.97485716e-12, 2.08739800e-11, 3.77910481e-12, 1.29583972e-11,\n",
       "       5.17245521e-12, 1.20809510e-11, 2.43557216e-11, 2.33009781e-11,\n",
       "       9.38764306e-12, 1.09005441e-11, 2.11329342e-12, 1.94889265e-11,\n",
       "       1.56065764e-11, 2.41374568e-11, 1.25806216e-11, 1.07659425e-11,\n",
       "       4.33881607e-12, 2.74798235e-12, 6.95739150e-12, 8.32683520e-12,\n",
       "       1.08679474e-12, 1.92294894e-12, 6.22849286e-12, 2.01675457e-11,\n",
       "       1.71314739e-11, 1.41408295e-11, 9.81640457e-12, 1.75184096e-12,\n",
       "       7.80271740e-12, 3.08279858e-12, 2.92402873e-12, 8.34747201e-12,\n",
       "       1.32984087e-11, 1.91929062e-11, 4.66881506e-12, 7.16396284e-14,\n",
       "       3.71180550e-12, 6.99376827e-13, 1.06688866e-13, 1.79524387e-12,\n",
       "       9.74448249e-12, 1.56679435e-11, 1.39216966e-11, 9.22524177e-12,\n",
       "       8.74535252e-12, 1.98539072e-12, 4.95458096e-13, 1.02915055e-11,\n",
       "       3.27530919e-36, 1.15942808e-11, 1.33009800e-11, 1.33009879e-11,\n",
       "       4.65483706e-36, 7.25645933e-37, 1.33009775e-11, 3.13296873e-36,\n",
       "       6.30858003e-37, 1.33009800e-11, 3.46396528e-37, 3.55266823e-37,\n",
       "       7.35424602e-37, 2.95247072e-37, 1.17905167e-36, 2.85588698e-37,\n",
       "       4.06130424e-12, 1.98187944e-11, 1.37769840e-11, 1.04476658e-11,\n",
       "       1.88107442e-11, 4.27418795e-37, 9.86260078e-37, 6.39768236e-37,\n",
       "       1.81896126e-36, 3.27181279e-37, 5.56103531e-37, 1.99897687e-36,\n",
       "       4.36426385e-37, 1.54672437e-11, 1.34531583e-11, 6.55433084e-12,\n",
       "       5.71223208e-38, 2.13933624e-37, 1.10950025e-36, 8.28503856e-37,\n",
       "       4.59471798e-37, 5.68391655e-37, 7.41326289e-37, 7.28229359e-37,\n",
       "       2.47418245e-37, 1.92982720e-36, 1.77267107e-37, 8.62673822e-37,\n",
       "       7.05762004e-37, 1.83049756e-36, 7.97015941e-38, 1.79909341e-12,\n",
       "       1.91704562e-36, 4.16281691e-12, 7.86428928e-12, 7.26079312e-12,\n",
       "       1.04239364e-11, 4.24849388e-12, 1.05703828e-12, 3.51047178e-12,\n",
       "       7.28088283e-12, 7.44742794e-13, 2.75542111e-12, 8.76874500e-12,\n",
       "       2.09694231e-13, 1.26647456e-11, 8.64960213e-12, 3.21110305e-12,\n",
       "       2.92292955e-11, 9.40333326e-12, 2.55744052e-11, 5.31465214e-12,\n",
       "       2.42317490e-11, 6.07230188e-13, 2.51041103e-11, 1.20648669e-11,\n",
       "       1.91047913e-11, 2.01776190e-37, 9.40333325e-12, 2.55744053e-11,\n",
       "       6.25012392e-12, 2.20571319e-11, 3.47929031e-11, 3.94323853e-12,\n",
       "       6.49821021e-12, 1.92033250e-12, 1.77642489e-11, 4.59936120e-12,\n",
       "       8.34478644e-13, 1.52842695e-11, 1.44539641e-11, 1.27562542e-38,\n",
       "       1.14056430e-12, 9.80895165e-39, 1.43013448e-12, 7.47687706e-12,\n",
       "       2.90784453e-12, 1.23563809e-12, 1.68372203e-11, 4.47532051e-12,\n",
       "       7.34282037e-12, 2.06827482e-11, 5.82919402e-12, 5.91570667e-12,\n",
       "       3.45773346e-11, 1.74269208e-12, 7.70333653e-12, 2.91542975e-11,\n",
       "       7.46624757e-12, 4.12132443e-12, 4.16997054e-12, 4.78831438e-39,\n",
       "       3.91842802e-12, 5.90711358e-39, 2.66550266e-12, 4.03536241e-14,\n",
       "       1.22966565e-11, 3.59317864e-12, 1.14517393e-11, 8.16532636e-12,\n",
       "       2.38005324e-11, 5.05604111e-12, 8.71650258e-12, 5.31527596e-39,\n",
       "       3.88245375e-38, 1.15308871e-38, 1.61702419e-38, 4.30225198e-39,\n",
       "       3.04345474e-38, 2.75062750e-39, 7.29376195e-39, 6.59533035e-40,\n",
       "       4.40494638e-39, 2.14500112e-39, 7.81120124e-40, 6.52273734e-40,\n",
       "       1.20108629e-39, 2.07924144e-39, 7.08915827e-40, 1.25185600e-11,\n",
       "       1.12020470e-11, 7.23187873e-12, 1.12134752e-11, 7.00057605e-12,\n",
       "       6.37620521e-12, 6.41637195e-13, 1.05459755e-11, 3.75977585e-12,\n",
       "       7.40380631e-12, 1.97508283e-11, 5.99674897e-12, 4.03244333e-11,\n",
       "       9.85033212e-12, 1.14455986e-39, 3.56273572e-12, 3.68120836e-12,\n",
       "       3.68117114e-12, 5.13767317e-40, 2.87568470e-39, 2.18950960e-11,\n",
       "       1.41526170e-11, 1.19659986e-11, 9.25706664e-12, 6.58362956e-40,\n",
       "       4.16281697e-12, 8.31585859e-41, 2.72940645e-40, 1.17023477e-11,\n",
       "       7.62525094e-41, 3.14488640e-42, 1.32100086e-11, 5.85781853e-12,\n",
       "       1.95924838e-59, 3.10812329e-11, 7.15908738e-17, 7.15908738e-17,\n",
       "       7.15908738e-17, 7.15908738e-17, 7.15908738e-17, 7.15908738e-17,\n",
       "       7.15908738e-17, 7.15908738e-17, 7.15908738e-17, 7.15908738e-17,\n",
       "       7.15908738e-17, 7.15908738e-17, 7.15908738e-17, 7.15908738e-17,\n",
       "       7.15908738e-17, 7.15908738e-17, 7.15908738e-17, 7.15908738e-17,\n",
       "       7.15908738e-17, 7.15908738e-17, 7.15908738e-17, 7.15908738e-17])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff = np.abs(coeff)\n",
    "coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f02d4400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.93048415048859e-13"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(coeff,0.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9a135c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True,  True, False, False, False, False, False,\n",
       "        True,  True,  True,  True,  True, False, False, False, False,\n",
       "        True, False, False, False,  True, False, False, False,  True,\n",
       "        True,  True,  True,  True, False, False, False, False,  True,\n",
       "       False, False, False,  True,  True, False, False, False,  True,\n",
       "        True, False, False, False,  True,  True, False, False, False,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False,  True, False,  True,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False,  True,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "       False,  True, False, False, False,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True, False, False, False, False,\n",
       "        True,  True,  True,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False,  True,  True, False,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True, False, False, False, False,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False,  True,  True,\n",
       "       False, False, False, False,  True, False,  True,  True, False,\n",
       "        True,  True, False, False,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_vec = coeff < 10**(-14)\n",
    "bool_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9909a791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R1MPART</th>\n",
       "      <th>R1MLEN</th>\n",
       "      <th>R1MCURLN</th>\n",
       "      <th>R1MLENM</th>\n",
       "      <th>R1MNEV</th>\n",
       "      <th>H1ANYFIN</th>\n",
       "      <th>H1ANYFAM</th>\n",
       "      <th>R1FAMR</th>\n",
       "      <th>R1FINR</th>\n",
       "      <th>H1HHRESP</th>\n",
       "      <th>...</th>\n",
       "      <th>RABPLACF_1</th>\n",
       "      <th>RADNEPI_0</th>\n",
       "      <th>RADNEPI_1</th>\n",
       "      <th>RADNEPI_2</th>\n",
       "      <th>RADNEPI_3</th>\n",
       "      <th>RADNEPI_5</th>\n",
       "      <th>RADNEPI_8</th>\n",
       "      <th>RAEVBRNF_0.0</th>\n",
       "      <th>RAEVBRNF_1.0</th>\n",
       "      <th>RAEVBRNF_3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6954</th>\n",
       "      <td>0.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10086</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31.9</td>\n",
       "      <td>31.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5407</th>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8716</th>\n",
       "      <td>0.0</td>\n",
       "      <td>41.3</td>\n",
       "      <td>41.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8552</th>\n",
       "      <td>0.0</td>\n",
       "      <td>29.7</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7356</th>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4649</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>0.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>315 rows × 799 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       R1MPART  R1MLEN  R1MCURLN  R1MLENM  R1MNEV  H1ANYFIN  H1ANYFAM  R1FAMR  \\\n",
       "6954       0.0    26.5       NaN      0.0     0.0       1.0       1.0     1.0   \n",
       "10086      1.0     0.0       NaN      0.0     1.0       1.0       1.0     1.0   \n",
       "1063       0.0    31.9      31.9      0.0     0.0       1.0       1.0     1.0   \n",
       "5407       0.0    32.0      32.0      0.0     0.0       1.0       1.0     0.0   \n",
       "8716       0.0    41.3      41.3      0.0     0.0       1.0       1.0     1.0   \n",
       "...        ...     ...       ...      ...     ...       ...       ...     ...   \n",
       "8552       0.0    29.7      29.7      0.0     0.0       1.0       1.0     1.0   \n",
       "2802       0.0    14.4       NaN      0.0     0.0       1.0       1.0     1.0   \n",
       "7356       0.0    27.0       3.4      0.0     0.0       1.0       1.0     1.0   \n",
       "4649       0.0    17.0      12.9      0.0     0.0       1.0       1.0     0.0   \n",
       "3200       0.0    19.5      19.5      0.0     0.0       1.0       1.0     1.0   \n",
       "\n",
       "       R1FINR  H1HHRESP  ...  RABPLACF_1  RADNEPI_0  RADNEPI_1  RADNEPI_2  \\\n",
       "6954      1.0       1.0  ...         0.0        1.0        0.0        0.0   \n",
       "10086     0.0       2.0  ...         0.0        1.0        0.0        0.0   \n",
       "1063      0.0       2.0  ...         0.0        1.0        0.0        0.0   \n",
       "5407      1.0       2.0  ...         0.0        1.0        0.0        0.0   \n",
       "8716      0.0       2.0  ...         0.0        1.0        0.0        0.0   \n",
       "...       ...       ...  ...         ...        ...        ...        ...   \n",
       "8552      1.0       2.0  ...         0.0        1.0        0.0        0.0   \n",
       "2802      1.0       1.0  ...         0.0        1.0        0.0        0.0   \n",
       "7356      0.0       2.0  ...         0.0        1.0        0.0        0.0   \n",
       "4649      0.0       2.0  ...         0.0        1.0        0.0        0.0   \n",
       "3200      0.0       2.0  ...         0.0        1.0        0.0        0.0   \n",
       "\n",
       "       RADNEPI_3  RADNEPI_5  RADNEPI_8  RAEVBRNF_0.0  RAEVBRNF_1.0  \\\n",
       "6954         0.0        0.0        0.0           1.0           0.0   \n",
       "10086        0.0        0.0        0.0           1.0           0.0   \n",
       "1063         0.0        0.0        0.0           1.0           0.0   \n",
       "5407         0.0        0.0        0.0           1.0           0.0   \n",
       "8716         0.0        0.0        0.0           1.0           0.0   \n",
       "...          ...        ...        ...           ...           ...   \n",
       "8552         0.0        0.0        0.0           1.0           0.0   \n",
       "2802         0.0        0.0        0.0           1.0           0.0   \n",
       "7356         0.0        0.0        0.0           1.0           0.0   \n",
       "4649         0.0        0.0        0.0           1.0           0.0   \n",
       "3200         0.0        0.0        0.0           1.0           0.0   \n",
       "\n",
       "       RAEVBRNF_3.0  \n",
       "6954            0.0  \n",
       "10086           0.0  \n",
       "1063            0.0  \n",
       "5407            0.0  \n",
       "8716            0.0  \n",
       "...             ...  \n",
       "8552            0.0  \n",
       "2802            0.0  \n",
       "7356            0.0  \n",
       "4649            0.0  \n",
       "3200            0.0  \n",
       "\n",
       "[315 rows x 799 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = liste[0]\n",
    "selected = columns[columns.columns[~bool_vec]]\n",
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6920ea24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6954    NaN\n",
       "10086   NaN\n",
       "1063    NaN\n",
       "5407    NaN\n",
       "8716    NaN\n",
       "         ..\n",
       "8552    NaN\n",
       "2802    NaN\n",
       "7356    NaN\n",
       "4649    NaN\n",
       "3200    NaN\n",
       "Name: REXITWV_14.0, Length: 315, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste[0][\"REXITWV_14.0\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
