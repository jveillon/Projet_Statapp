{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of the Lasso With High Missing Rate."
      ],
      "metadata": {
        "id": "wm5MwpWa5oim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this notebook is to implement the lasso with high missing rate described [here](https://www.ijcai.org/proceedings/2019/0491.pdf). "
      ],
      "metadata": {
        "id": "BMpYFpPn5v0U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "ZZL0jO1Q7HvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import cvxpy as cp\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "pVnwGrET6JQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HMLasso"
      ],
      "metadata": {
        "id": "6FEfUyv87Lsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HMLasso():\n",
        "  \"\"\"\n",
        "  Lasso regularization that performs well with high missing rate.\n",
        "\n",
        "  Implemented according to the related article 'HMLasso: Lasso with High Missing\n",
        "  Rate' by Masaaki Takada1, Hironori Fujisawa and Takeichiro Nishikawa.\n",
        "  Link to the article: https://www.ijcai.org/proceedings/2019/0491.pdf\n",
        "\n",
        "  ------------\n",
        "  Common uses: Once fitted, the HMLasso can provide linear predictions. \n",
        "  It can also be used to select variables of interest from the given data. This \n",
        "  second goal can be achieved through selection of variables whose coefficient\n",
        "  is almost (or equal to) zero.\n",
        "\n",
        "  Please note that no metric is implemented in this class for now. \n",
        "  See sklearn.metrics.mean_squared_error or like for useful metrics.\n",
        "\n",
        "  ------------\n",
        "  Parameters:\n",
        "      mu : float/int, default=1.0: the hyperparameter that control how\n",
        "      parcimonious the model shall be. The larger mu is, the greater the\n",
        "      regularization will be (hence the calculated beta_opt might \n",
        "      present more nullified coefficients). mu must be positive.\n",
        "      \n",
        "      alpha : float/int, default=1: the hyperparameter that control weights\n",
        "      importance. Be wary that setting alpha > 5 can make convergence way\n",
        "      slower, as the weights become closer and closer to 0 and as the numerical\n",
        "      solver has more and more trouble converging.\n",
        "      One may prefer setting alpha in the range [0., 3.]. Common values\n",
        "      of alpha are 0., 0.5, 1. with the latter experimentally delivering best\n",
        "      performances. alpha must be positive.\n",
        "      See source article for more.\n",
        "\n",
        "      verbose : float/int, default=1: control how much verbose\n",
        "      is displayed. Encoded values are 0, 1 and 2. If verbose > 2, there\n",
        "      will be no difference with verbose=2 display.\n",
        "  \n",
        "  ------------\n",
        "  Methods:\n",
        "      fit(self, X, y):\n",
        "        Fit the HMLasso on (X, y)\n",
        "        X, the features, must be a mean-centered numpy array of shape (n, p)\n",
        "        y, the labels, must be a vector of shape (n, 1) or (n,)\n",
        "\n",
        "        Do not return anything. However, once the fitting is done, one can\n",
        "        use 'predict' method to predict any given output using the linear model.\n",
        "      \n",
        "      predict(self, X):\n",
        "        Predict using linear model.\n",
        "        Return the predicted vector.\n",
        "  \n",
        "  ------------\n",
        "  Constants:\n",
        "      beta_opt: the estimator.\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, mu=1, alpha=1, verbose=1):\n",
        "\n",
        "    assert type(mu) is int or type(mu) is float, \"mu must be a number.\"\n",
        "    assert type(alpha) is int or type(alpha) is float, \"alpha must be a number.\"\n",
        "    assert type(verbose) is int, \"verbose must be an integer.\"\n",
        "    assert mu >= 0, \"mu must be a positive number.\"\n",
        "    assert alpha >= 0, \"alpha must be a positive number.\"\n",
        "\n",
        "    self.mu = mu\n",
        "    self.alpha = alpha\n",
        "    self.verbose = verbose\n",
        "    \n",
        "    self.n = None\n",
        "    self.p = None\n",
        "    self.S_pair = None\n",
        "    self.rho_pair = None\n",
        "    self.R = None\n",
        "    self.Sigma_opt = None\n",
        "    self.beta_opt = None\n",
        "\n",
        "    self.isFirstProblemSolved = False\n",
        "    self.isSecondProblemSolved = False # Unused at the moment.\n",
        "    self.isFitted = False\n",
        "  \n",
        "  def predict(self, X):\n",
        "    \"\"\"\n",
        "    Predict using the linear model.\n",
        "\n",
        "    ------------\n",
        "    Parameters:\n",
        "        X : 2D numpy array\n",
        "\n",
        "    Returns:\n",
        "        y : 1D numpy array\n",
        "    \"\"\"\n",
        "\n",
        "    assert self.isFitted, \"The model has not yet been fitted.\"\n",
        "    assert X.shape[1] == self.p, f\"Given data is of dimension {X.shape[1]}. Must have dimension {self.p}).\"\n",
        "    assert not np.isnan(X).any(), \"Input contains NaN.\"\n",
        "\n",
        "    return np.dot(X, self.beta_opt)\n",
        "  \n",
        "  def fit(self, X, y):\n",
        "    \"\"\"\n",
        "    Fit the HMLasso on (X, y).\n",
        "\n",
        "    ------------\n",
        "    Parameters:\n",
        "        X : 2D numpy array, shape (n,p). It corresponds to the features, and\n",
        "        must be mean-centered.\n",
        "        y : 1D numpy array, shape (n,1) or (n,). It corresponds to the labels.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    \n",
        "    assert type(X) == np.ndarray, \"Features are not a numpy array.\"\n",
        "    assert type(y) == np.ndarray, \"Labels are not a numpy array\"\n",
        "    assert X.shape[0] == y.shape[0], \"Features and labels shapes are not compatibles.\"\n",
        "    assert len(y.shape) == 1, \"Labels are not a vector.\"\n",
        "\n",
        "    self.n, self.p = X.shape    \n",
        "    self.__verify_centering__(X)\n",
        "    self.S_pair, self.rho_pair, self.R = self.__impute_params__(X, y)\n",
        "    self.Sigma_opt = self.__solve_first_problem__()\n",
        "\n",
        "    # It appears that, due to floating points exceptions, Sigma_opt is not always\n",
        "    # Positive semidefinite. Hence, we shall check it.\n",
        "    eigenvalues = np.linalg.eig(self.Sigma_opt)[0]\n",
        "    min_eigenvalue = min(eigenvalues)\n",
        "    if min_eigenvalue < 0:\n",
        "      print(f\"[Warning] Sigma_opt is not PSD, its minimum eigenvalue is {min_eigenvalue}. Error handled by adding {-min_eigenvalue} to each eigenvalue.\")\n",
        "      self.Sigma_opt = self.Sigma_opt - min_eigenvalue * np.eye(self.p, self.p)\n",
        "    \n",
        "    self.beta_opt = self.__solve_second_problem__()\n",
        "\n",
        "    self.isFitted = True\n",
        "\n",
        "    if self.verbose > 0:\n",
        "      print(\"Model fitted.\")\n",
        "\n",
        "  def __verify_centering__(self, X, tolerance=1e-8):\n",
        "    for col in range(self.p):\n",
        "      current_mean = X[:, col].mean()\n",
        "      if abs(current_mean) > tolerance:\n",
        "        raise Exception(f\"Data is not centered: column {col} has mean of {current_mean}\")\n",
        "  \n",
        "  def __impute_params__(self, X, y):\n",
        "\n",
        "    if self.verbose > 0:\n",
        "      print(\"[Imputing parameters] Starting...\")\n",
        "\n",
        "    Z = np.nan_to_num(X)\n",
        "    Y = (Z != 0).astype(int)\n",
        "    R = np.dot(Y.T, Y)\n",
        "    if self.verbose > 1:\n",
        "      print(\"[Imputing parameters] R calculated.\")\n",
        "\n",
        "    rho_pair = np.divide(np.dot(Z.T, y), R.diagonal())\n",
        "    if self.verbose > 1:\n",
        "      print(\"[Imputing parameters] rho_pair calculated.\")\n",
        "\n",
        "    S_pair = np.divide(np.dot(Z.T, Z), R)\n",
        "    if self.verbose > 1:\n",
        "      print(\"[Imputing parameters] S_pair calculated.\")\n",
        "\n",
        "    R = R / self.n\n",
        "\n",
        "    if self.alpha > 5:\n",
        "      print(\"[Warning] The hyperparameter alpha={} is large (greater than 5), which might make convergence way slower.\")\n",
        "    R = np.power(R, self.alpha)\n",
        "\n",
        "    if self.verbose > 0:\n",
        "      print(\"[Imputing parameters] Parameters imputed.\")\n",
        "\n",
        "    return S_pair, rho_pair, R\n",
        "\n",
        "\n",
        "  def __solve_first_problem__(self):\n",
        "    \n",
        "    assert self.S_pair is not None, \"Pairwise covariance matrix of features is not determined.\"\n",
        "    assert self.rho_pair is not None, \"Pairwise covariance vector of features and labels is not determined.\"\n",
        "    assert self.R is not None, \"Weights are not determined.\"\n",
        "\n",
        "    if self.verbose > 0:\n",
        "      print(\"[First Problem] Starting...\")\n",
        "\n",
        "    Sigma = cp.Variable((self.p, self.p), PSD = True) # Variable to optimize\n",
        "    obj = cp.Minimize(cp.sum_squares(cp.multiply(self.R, Sigma-self.S_pair))) # Objective to minimize\n",
        "    constraints = [Sigma >> 0] # Constraints: We want Sigma to be positive semi-definite.\n",
        "    if self.verbose > 1:\n",
        "      print(\"[First Problem] Objective and constraints well-defined.\")\n",
        "\n",
        "    # Solve the optimization problem\n",
        "    prob = cp.Problem(obj, constraints)\n",
        "    prob.solve()\n",
        "    if self.verbose > 1:\n",
        "      print(f\"[First Problem] Problem status: {prob.status}.\")\n",
        "    if self.verbose > 0:\n",
        "      print(\"[First Problem] Problem solved.\")\n",
        "\n",
        "    self.isFirstProblemSolved = True\n",
        "\n",
        "    return Sigma.value\n",
        "\n",
        "  def __solve_second_problem__(self):\n",
        "    \n",
        "    assert self.S_pair is not None, \"Pairwise covariance matrix of features is not determined.\"\n",
        "    assert self.rho_pair is not None, \"Pairwise covariance vector of features and labels is not determined.\"\n",
        "    assert self.R is not None, \"Weights are not determined.\"\n",
        "    assert self.isFirstProblemSolved, \" First optimization problem has not been solved.\"\n",
        "    assert self.Sigma_opt is not None, \"Sigma_opt is unknown. First optimization problem might have not been solved.\"\n",
        "\n",
        "    if self.verbose > 0:\n",
        "      print(\"[Second Problem] Starting...\")\n",
        "\n",
        "    beta = cp.Variable(self.p) # Variable to optimize\n",
        "    obj = cp.Minimize(0.5 * cp.quad_form(beta, self.Sigma_opt) - self.rho_pair.T @ beta + self.mu * cp.norm1(beta)) # Objective to minimize\n",
        "    constraints = [] # Constraints\n",
        "    if self.verbose > 1:\n",
        "      print(\"[Second Problem] Objective and constraints well-defined.\")\n",
        "\n",
        "    # Solve the optimization problem\n",
        "    prob = cp.Problem(obj, constraints)\n",
        "    prob.solve()\n",
        "    if self.verbose > 1:\n",
        "      print(f\"[Second Problem] Problem status: {prob.status}.\")\n",
        "    if self.verbose > 0:\n",
        "      print(\"[Second Problem] Problem solved.\\n\")\n",
        "    \n",
        "    self.isSecondProblemSolved = True\n",
        "\n",
        "    return beta.value"
      ],
      "metadata": {
        "id": "sSdRL-Gm9xgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "b6zl4SdSi4TZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_Xy(n, p, replace_rate=0.3):\n",
        "  X = 100*np.random.rand(n,p) # Generate random X\n",
        "  y = 7*X[:, 0] - 2 * X[:, 1] + 5 * X[:, 2] + 19 * X[:, 3] + 6*X[:, 4]\n",
        "  \n",
        "  indices = np.full(X.shape, False, bool)\n",
        "  mask = np.random.choice([False, True], size=X.shape, p=((1 - replace_rate), replace_rate))\n",
        "  X[mask] = np.nan\n",
        "\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "5mmg3-ifVCFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  X, y = get_Xy(10000, 300, 0.4)\n",
        "\n",
        "  scaler = StandardScaler(with_std=False)\n",
        "  X_scaled = scaler.fit_transform(X)\n",
        "  lasso = HMLasso(mu=100, alpha=1, verbose=2)\n",
        "  lasso.fit(X_scaled, y)\n",
        "  X_test, y_test = get_Xy(10000, 300, replace_rate=0.)\n",
        "  print(f\"error = {np.sqrt(mean_squared_error(y_test, lasso.predict(X_test)))}\\n\")\n",
        "  print(lasso.beta_opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzjr9L-GqN4O",
        "outputId": "33daa9f5-522d-424a-a185-6b8eef775013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Imputing parameters] Starting...\n",
            "[Imputing parameters] R calculated.\n",
            "[Imputing parameters] rho_pair calculated.\n",
            "[Imputing parameters] S_pair calculated.\n",
            "[Imputing parameters] Parameters imputed.\n",
            "[First Problem] Starting...\n",
            "[First Problem] Objective and constraints well-defined.\n",
            "[First Problem] Problem status: optimal.\n",
            "[First Problem] Problem solved.\n",
            "[Second Problem] Starting...\n",
            "[Second Problem] Objective and constraints well-defined.\n",
            "[Second Problem] Problem status: optimal.\n",
            "[Second Problem] Problem solved.\n",
            "\n",
            "Model fitted.\n",
            "error = 146.63104467269756\n",
            "\n",
            "[ 6.98666394e+00 -2.27712419e+00  5.19699658e+00  1.92963987e+01\n",
            "  5.98226063e+00  1.88838848e-01 -6.48952486e-02  2.98950197e-02\n",
            "  2.15578398e-01  3.58109637e-22  2.10340892e-22 -4.01499695e-02\n",
            "  2.33991120e-01  3.49529665e-01  4.19396129e-02  7.00962268e-02\n",
            " -8.52670408e-22  3.27357049e-01  4.53081559e-22 -4.75271331e-22\n",
            "  1.93999076e-01  9.90546476e-22 -4.91141598e-02  5.84393993e-02\n",
            "  2.49900221e-02 -3.30919101e-24 -9.08538746e-22  5.58572941e-02\n",
            " -1.79459267e-21 -1.57348235e-22  9.40083255e-02 -4.37903466e-22\n",
            " -6.75309611e-22  8.43662024e-02  5.69254679e-22  1.67762054e-01\n",
            "  7.77699952e-02 -2.84738950e-01 -1.60594023e-01  9.91486120e-22\n",
            "  1.39520975e-02 -8.11360409e-02  1.48472339e-22 -6.12875959e-02\n",
            " -4.62345374e-03  1.24108581e-21  2.26059027e-01 -2.00613725e-01\n",
            "  3.09822560e-01  9.79512362e-02  8.60208796e-22  2.96229571e-02\n",
            " -2.87460070e-22 -1.46189867e-01  2.47188032e-01  1.75766781e-22\n",
            "  1.66962319e-01 -9.27649254e-22  3.29462808e-01  7.42129087e-02\n",
            "  1.21940046e-01  2.48764060e-01  5.43024719e-03 -6.87006969e-02\n",
            " -1.06107691e-01 -2.82747078e-01  2.76249493e-01  2.82204830e-22\n",
            " -4.34443468e-22 -9.26442726e-22 -3.98279001e-03  1.18740588e-01\n",
            " -1.24961976e-21 -1.16546907e-01  1.72493513e-01  4.52897859e-22\n",
            "  4.57202863e-22 -1.23963489e-21  7.29768801e-02 -5.33867837e-22\n",
            " -8.37601130e-22 -2.73602987e-01  7.66123321e-22 -1.23087505e-01\n",
            " -2.20147397e-22  1.02625505e-01 -1.06928472e-21  2.55049274e-21\n",
            " -1.51171478e-23 -2.34430352e-01 -2.09190347e-02 -7.80151425e-02\n",
            " -2.56337888e-01 -1.65115822e-23 -2.50777476e-01 -6.78678617e-02\n",
            " -9.64515591e-22 -2.18255923e-02  8.05119417e-22  4.80662730e-02\n",
            "  3.96416084e-22  1.12582382e-21 -1.74393602e-01  2.91567983e-01\n",
            "  8.47247234e-22  2.37221148e-01  1.16720798e-01 -1.79049912e-21\n",
            " -2.42888691e-01  3.33367484e-02 -5.06012640e-22 -1.05537686e-01\n",
            " -1.08240151e-21 -3.77866714e-22 -5.65493429e-22 -3.57486444e-01\n",
            "  1.85365994e-01  6.96867487e-22 -1.65951930e-01  9.64185902e-02\n",
            " -6.07907357e-02  3.34765305e-01  1.25884207e-01  1.19431340e-21\n",
            " -5.12059152e-22 -1.74416495e-01  1.43477308e-01  2.19148543e-01\n",
            " -2.17224930e-21  8.07055819e-22 -7.53914022e-02  6.68239352e-02\n",
            " -9.51848658e-02 -3.58527960e-02  8.29891345e-22  3.86216076e-01\n",
            "  5.56437974e-22  5.56137264e-22 -3.19285238e-22  5.09812774e-02\n",
            "  2.41374728e-22  4.44182343e-22  2.78278036e-01 -2.25716804e-02\n",
            " -1.65522674e-01  3.85284022e-02 -2.66557265e-22 -4.94240108e-02\n",
            "  9.88149115e-02  1.83944320e-01 -3.03358058e-01 -2.11489883e-01\n",
            " -8.44761425e-22  8.96293823e-02 -2.17999018e-01 -5.48175516e-01\n",
            "  3.15252451e-02  8.98455663e-22  6.85928004e-02 -1.01981363e-01\n",
            " -1.08194619e-21 -6.71143558e-03  4.85443000e-02  9.13671511e-03\n",
            "  2.16780822e-22  5.17304151e-02 -7.20165305e-02  1.42168120e-02\n",
            " -2.31775028e-01  2.72684999e-01  1.42218659e-21 -2.15895201e-22\n",
            "  1.13774371e-01  7.35531846e-24 -9.73651900e-02  1.51072593e-01\n",
            "  1.46802713e-01 -8.94060777e-22 -1.00369328e-21 -1.03114779e-01\n",
            " -2.30894386e-01  2.82571617e-01  1.56169632e-02 -9.32865843e-02\n",
            "  3.39142964e-22  7.48965674e-22 -1.07398473e-02  9.62384341e-03\n",
            " -1.24035478e-21  4.33799909e-02 -6.01031745e-23 -3.10203612e-01\n",
            " -2.45655737e-01 -1.66495239e-22  7.24688038e-02  3.19131412e-02\n",
            " -7.61088394e-22 -7.13819749e-02 -1.08852536e-21 -5.52056282e-22\n",
            "  1.05075869e-21 -8.11659142e-02 -4.56128729e-22 -1.44187632e-01\n",
            " -1.03088293e-01  2.06039264e-22 -1.14400016e-23 -8.52140487e-22\n",
            " -2.03427219e-01 -2.41680304e-01  1.74651212e-01  4.39120187e-22\n",
            " -4.25184872e-23  5.71112884e-23  9.30502005e-24  9.86343499e-22\n",
            " -2.17085937e-02 -1.30389567e-01  1.17110184e-01  9.73922392e-22\n",
            "  1.66437384e-22  1.94046649e-01 -4.75366124e-22  4.13222950e-22\n",
            "  5.56919238e-02 -7.59103402e-22 -1.67109736e-01 -8.59381020e-22\n",
            "  1.07296660e-21  1.13773906e-01  2.01613239e-22  9.68943932e-02\n",
            "  1.70304136e-01  2.34190680e-01 -3.36558547e-22  1.89791510e-01\n",
            "  1.96388947e-01  1.12093216e-22 -2.68848868e-01  1.30540555e-01\n",
            " -4.12565117e-01 -1.72862306e-03  1.01995960e-01  7.59490920e-02\n",
            "  2.70498603e-01 -1.02468202e-21  2.97717476e-22  7.47927576e-02\n",
            "  1.22501540e-02 -2.09394876e-01  8.70355493e-02 -7.30194604e-22\n",
            "  2.21231469e-02 -9.65513552e-22 -1.30707360e-21  2.90182582e-22\n",
            "  1.69717190e-22 -1.35260306e-21 -2.05565394e-02 -1.97813734e-01\n",
            "  2.09036789e-22  1.86906503e-21  4.77278930e-22  5.57687401e-02\n",
            "  5.42283741e-24  1.24583738e-01  3.05941894e-22  1.45383322e-01\n",
            "  4.83249300e-01  3.16191302e-02 -3.35248849e-22  1.07492085e-21\n",
            "  2.52081266e-01  6.37669058e-03  2.22314081e-22  1.53510299e-02\n",
            " -6.66523593e-02 -6.38859056e-22  1.85773545e-01 -1.14198878e-21\n",
            " -1.40527036e-01  2.52828009e-02  1.30572103e-02  1.23694283e-21\n",
            " -1.68767749e-02 -1.34135378e-01 -1.97689836e-22 -6.79262652e-02\n",
            " -6.32477306e-02  3.53928308e-01  1.77898707e-01  1.18759940e-02\n",
            "  2.23387815e-02 -1.13565530e-01 -2.31869897e-02  9.11373323e-24\n",
            " -2.50393003e-01 -1.32931831e-01 -4.62729014e-22 -2.53142562e-01]\n"
          ]
        }
      ]
    }
  ]
}