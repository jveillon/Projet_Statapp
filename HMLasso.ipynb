{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of the Lasso With High Missing Rate."
      ],
      "metadata": {
        "id": "wm5MwpWa5oim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this notebook is to implement the lasso with high missing rate described [here](https://www.ijcai.org/proceedings/2019/0491.pdf). "
      ],
      "metadata": {
        "id": "BMpYFpPn5v0U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "ZZL0jO1Q7HvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import cvxpy as cp\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "pVnwGrET6JQB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HMLasso"
      ],
      "metadata": {
        "id": "6FEfUyv87Lsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HMLasso():\n",
        "  \"\"\"\n",
        "  Lasso regularization that performs well with high missing rate.\n",
        "\n",
        "  Implemented according to the related article 'HMLasso: Lasso with High Missing\n",
        "  Rate' by Masaaki Takada1, Hironori Fujisawa and Takeichiro Nishikawa.\n",
        "  Link to the article: https://www.ijcai.org/proceedings/2019/0491.pdf\n",
        "\n",
        "  ------------\n",
        "  Common uses: Once fitted, the HMLasso can provide linear predictions. \n",
        "  It can also be used to select variables of interest from the given data. This \n",
        "  second goal can be achieved through selection of variables whose coefficient\n",
        "  is almost (or equal to) zero.\n",
        "\n",
        "  Please note that no metric is implemented in this class for now. \n",
        "  See sklearn.metrics.mean_squared_error or like for useful metrics.\n",
        "\n",
        "  ------------\n",
        "  Parameters:\n",
        "      mu : float/int, default=1.0: the hyperparameter that control how\n",
        "      parcimonious the model shall be. The larger mu is, the greater the\n",
        "      regularization will be (hence the calculated beta_opt might \n",
        "      present more nullified coefficients). mu must be positive.\n",
        "      \n",
        "      alpha : float/int, default=1: the hyperparameter that control weights\n",
        "      importance. Be wary that setting alpha > 5 can make convergence way\n",
        "      slower, as the weights become closer and closer to 0 and as the numerical\n",
        "      solver has more and more trouble converging.\n",
        "      One may prefer setting alpha in the range [0., 3.]. Common values\n",
        "      of alpha are 0., 0.5, 1. with the latter experimentally delivering best\n",
        "      performances. alpha must be positive.\n",
        "      See source article for more.\n",
        "\n",
        "      verbose : float/int, default=1: control how much verbose\n",
        "      is displayed. Encoded values are 0, 1 and 2. If verbose > 2, there\n",
        "      will be no difference with verbose=2 display.\n",
        "  \n",
        "  ------------\n",
        "  Methods:\n",
        "      fit(self, X, y):\n",
        "        Fit the HMLasso on (X, y)\n",
        "        X, the features, must be a mean-centered numpy array of shape (n, p)\n",
        "        y, the labels, must be a vector of shape (n, 1) or (n,)\n",
        "\n",
        "        Do not return anything. However, once the fitting is done, one can\n",
        "        use 'predict' method to predict any given output using the linear model.\n",
        "      \n",
        "      predict(self, X):\n",
        "        Predict using linear model.\n",
        "        Return the predicted vector.\n",
        "  \n",
        "  ------------\n",
        "  Constants:\n",
        "      beta_opt: the estimator.\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, mu=1, alpha=1, verbose=1):\n",
        "\n",
        "    assert type(mu) is int or type(mu) is float, \"mu must be a number.\"\n",
        "    assert type(alpha) is int or type(alpha) is float, \"alpha must be a number.\"\n",
        "    assert type(verbose) is int, \"verbose must be an integer.\"\n",
        "    assert mu >= 0, \"mu must be a positive number.\"\n",
        "    assert alpha >= 0, \"alpha must be a positive number.\"\n",
        "\n",
        "    self.mu = mu\n",
        "    self.alpha = alpha\n",
        "    self.verbose = verbose\n",
        "    \n",
        "    self.n = None\n",
        "    self.p = None\n",
        "    self.S_pair = None\n",
        "    self.rho_pair = None\n",
        "    self.R = None\n",
        "    self.Sigma_opt = None\n",
        "    self.beta_opt = None\n",
        "\n",
        "    self.isFirstProblemSolved = False\n",
        "    self.isSecondProblemSolved = False # Unused at the moment.\n",
        "    self.isFitted = False\n",
        "  \n",
        "  def predict(self, X):\n",
        "    \"\"\"\n",
        "    Predict using the linear model.\n",
        "\n",
        "    ------------\n",
        "    Parameters:\n",
        "        X : 2D numpy array\n",
        "\n",
        "    Returns:\n",
        "        y : 1D numpy array\n",
        "    \"\"\"\n",
        "\n",
        "    assert self.isFitted, \"The model has not yet been fitted.\"\n",
        "    assert X.shape[1] == self.p, f\"Given data is of dimension {X.shape[1]}. Must have dimension {self.p}).\"\n",
        "    assert not np.isnan(X).any(), \"Input contains NaN.\"\n",
        "\n",
        "    return np.dot(X, self.beta_opt)\n",
        "  \n",
        "  def fit(self, X, y):\n",
        "    \"\"\"\n",
        "    Fit the HMLasso on (X, y).\n",
        "\n",
        "    ------------\n",
        "    Parameters:\n",
        "        X : 2D numpy array, shape (n,p). It corresponds to the features, and\n",
        "        must be mean-centered.\n",
        "        y : 1D numpy array, shape (n,1) or (n,). It corresponds to the labels.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    \n",
        "    assert type(X) == np.ndarray, \"Features are not a numpy array.\"\n",
        "    assert type(y) == np.ndarray, \"Labels are not a numpy array\"\n",
        "    assert X.shape[0] == y.shape[0], \"Features and labels shapes are not compatibles.\"\n",
        "    assert len(y.shape) == 1, \"Labels are not a vector.\"\n",
        "\n",
        "    self.n, self.p = X.shape    \n",
        "    self.__verify_centering__(X)\n",
        "    self.S_pair, self.rho_pair, self.R = self.__impute_params__(X, y)\n",
        "    self.Sigma_opt = self.__solve_first_problem__()\n",
        "\n",
        "    # It appears that, due to floating points exceptions, Sigma_opt is not always\n",
        "    # Positive semidefinite. Hence, we shall check it.\n",
        "    eigenvalues = np.linalg.eig(self.Sigma_opt)[0]\n",
        "    min_eigenvalue = min(eigenvalues)\n",
        "    if min_eigenvalue < 0:\n",
        "      print(f\"[Warning] Sigma_opt is not PSD, its minimum eigenvalue is {min_eigenvalue}. Error handled by adding {-min_eigenvalue} to each eigenvalue.\")\n",
        "      self.Sigma_opt = self.Sigma_opt - min_eigenvalue* np.eye(self.p, self.p)\n",
        "    \n",
        "    self.beta_opt = self.__solve_second_problem__()\n",
        "\n",
        "    self.isFitted = True\n",
        "\n",
        "    if self.verbose > 0:\n",
        "      print(\"Model fitted.\")\n",
        "\n",
        "  def __verify_centering__(self, X, tolerance=1e-8):\n",
        "    for col in range(self.p):\n",
        "      current_mean = X[:, col].mean()\n",
        "      if abs(current_mean) > tolerance:\n",
        "        raise Exception(f\"Data is not centered: column {col} has mean of {current_mean}\")\n",
        "  \n",
        "  def __impute_params__(self, X, y):\n",
        "\n",
        "    if self.verbose > 0:\n",
        "      print(\"[Imputing parameters] Starting...\")\n",
        "\n",
        "    Z = np.nan_to_num(X)\n",
        "    Y = (Z != 0).astype(int)\n",
        "    R = np.dot(Y.T, Y)\n",
        "    if self.verbose > 1:\n",
        "      print(\"[Imputing parameters] R calculated.\")\n",
        "\n",
        "    rho_pair = np.divide(np.dot(Z.T, y), R.diagonal())\n",
        "    if self.verbose > 1:\n",
        "      print(\"[Imputing parameters] rho_pair calculated.\")\n",
        "\n",
        "    S_pair = np.divide(np.dot(Z.T, Z), R)\n",
        "    \n",
        "    if self.verbose > 1:\n",
        "      print(\"[Imputing parameters] S_pair calculated.\")\n",
        "\n",
        "    R = R / self.n\n",
        "\n",
        "    if self.alpha > 5:\n",
        "      print(\"[Warning] The hyperparameter alpha={} is large (greater than 5), which might make convergence way slower.\")\n",
        "    R = np.power(R, self.alpha)\n",
        "\n",
        "    if self.verbose > 0:\n",
        "      print(\"[Imputing parameters] Parameters imputed.\")\n",
        "\n",
        "    return S_pair, rho_pair, R\n",
        "\n",
        "\n",
        "  def __solve_first_problem__(self):\n",
        "    \n",
        "    assert self.S_pair is not None, \"Pairwise covariance matrix of features is not determined.\"\n",
        "    assert self.rho_pair is not None, \"Pairwise covariance vector of features and labels is not determined.\"\n",
        "    assert self.R is not None, \"Weights are not determined.\"\n",
        "\n",
        "    if self.verbose > 0:\n",
        "      print(\"[First Problem] Starting...\")\n",
        "\n",
        "    Sigma = cp.Variable((self.p, self.p), PSD = True) # Variable to optimize\n",
        "    obj = cp.Minimize(cp.sum_squares(cp.multiply(self.R, Sigma-self.S_pair))) # Objective to minimize\n",
        "    constraints = [Sigma >> 0] # Constraints: We want Sigma to be positive semi-definite.\n",
        "    if self.verbose > 1:\n",
        "      print(\"[First Problem] Objective and constraints well-defined.\")\n",
        "\n",
        "    # Solve the optimization problem\n",
        "    prob = cp.Problem(obj, constraints)\n",
        "    prob.solve()\n",
        "    if self.verbose > 1:\n",
        "      print(f\"[First Problem] Problem status: {prob.status}.\")\n",
        "    if self.verbose > 0:\n",
        "      print(\"[First Problem] Problem solved.\")\n",
        "\n",
        "    self.isFirstProblemSolved = True\n",
        "\n",
        "    return Sigma.value\n",
        "\n",
        "  def __solve_second_problem__(self):\n",
        "    \n",
        "    assert self.S_pair is not None, \"Pairwise covariance matrix of features is not determined.\"\n",
        "    assert self.rho_pair is not None, \"Pairwise covariance vector of features and labels is not determined.\"\n",
        "    assert self.R is not None, \"Weights are not determined.\"\n",
        "    assert self.isFirstProblemSolved, \" First optimization problem has not been solved.\"\n",
        "    assert self.Sigma_opt is not None, \"Sigma_opt is unknown. First optimization problem might have not been solved.\"\n",
        "\n",
        "    if self.verbose > 0:\n",
        "      print(\"[Second Problem] Starting...\")\n",
        "\n",
        "    beta = cp.Variable(self.p) # Variable to optimize\n",
        "    obj = cp.Minimize(0.5 * cp.quad_form(beta, self.Sigma_opt) - self.rho_pair.T @ beta + self.mu * cp.norm1(beta)) # Objective to minimize\n",
        "    constraints = [] # Constraints\n",
        "    if self.verbose > 1:\n",
        "      print(\"[Second Problem] Objective and constraints well-defined.\")\n",
        "\n",
        "    # Solve the optimization problem\n",
        "    prob = cp.Problem(obj, constraints)\n",
        "    prob.solve()\n",
        "    if self.verbose > 1:\n",
        "      print(f\"[Second Problem] Problem status: {prob.status}.\")\n",
        "    if self.verbose > 0:\n",
        "      print(\"[Second Problem] Problem solved.\\n\")\n",
        "    \n",
        "    self.isFirstProblemSolved = True\n",
        "\n",
        "    return beta.value"
      ],
      "metadata": {
        "id": "sSdRL-Gm9xgh"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "b6zl4SdSi4TZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(HMLasso)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFQnfhXSkA9u",
        "outputId": "a7f07842-e90a-4f5e-cb15-d38f9b96337b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class HMLasso in module __main__:\n",
            "\n",
            "class HMLasso(builtins.object)\n",
            " |  HMLasso(mu=1, alpha=1, verbose=1)\n",
            " |  \n",
            " |  Lasso regularization that performs well with high missing rate.\n",
            " |  \n",
            " |  Implemented according to the related article 'HMLasso: Lasso with High Missing\n",
            " |  Rate' by Masaaki Takada1, Hironori Fujisawa and Takeichiro Nishikawa.\n",
            " |  Link to the article: https://www.ijcai.org/proceedings/2019/0491.pdf\n",
            " |  \n",
            " |  ------------\n",
            " |  Common uses: Once fitted, the HMLasso can provide linear predictions. \n",
            " |  It can also be used to select variables of interest from the given data. This \n",
            " |  second goal can be achieved through selection of variables whose coefficient\n",
            " |  is almost (or equal to) zero.\n",
            " |  \n",
            " |  Please note that no metric is implemented in this class for now. \n",
            " |  See sklearn.metrics.mean_squared_error or like for useful metrics.\n",
            " |  \n",
            " |  ------------\n",
            " |  Parameters:\n",
            " |      mu : float/int, default=1.0: the hyperparameter that control how\n",
            " |      parcimonious the model shall be. The larger mu is, the greater the\n",
            " |      regularization will be (hence the calculated beta_opt might \n",
            " |      present more nullified coefficients). mu must be positive.\n",
            " |      \n",
            " |      alpha : float/int, default=1: the hyperparameter that control weights\n",
            " |      importance. Be wary that setting alpha > 5 can make convergence way\n",
            " |      slower, as the weights become closer and closer to 0 and as the numerical\n",
            " |      solver has more and more trouble converging.\n",
            " |      One may prefer setting alpha in the range [0., 3.]. Common values\n",
            " |      of alpha are 0., 0.5, 1. with the latter experimentally delivering best\n",
            " |      performances. alpha must be positive.\n",
            " |      See source article for more.\n",
            " |  \n",
            " |      verbose : float/int, default=1: control how much verbose\n",
            " |      is displayed. Encoded values are 0, 1 and 2. If verbose > 2, there\n",
            " |      will be no difference with verbose=2 display.\n",
            " |  \n",
            " |  ------------\n",
            " |  Methods:\n",
            " |      fit(self, X, y):\n",
            " |        Fit the HMLasso on (X, y)\n",
            " |        X, the features, must be a mean-centered numpy array of shape (n, p)\n",
            " |        y, the labels, must be a vector of shape (n, 1) or (n,)\n",
            " |  \n",
            " |        Do not return anything. However, once the fitting is done, one can\n",
            " |        use 'predict' method to predict any given output using the linear model.\n",
            " |      \n",
            " |      predict(self, X):\n",
            " |        Predict using linear model.\n",
            " |        Return the predicted vector.\n",
            " |  \n",
            " |  ------------\n",
            " |  Constants:\n",
            " |      beta_opt: the estimator.\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __impute_params__(self, X, y)\n",
            " |  \n",
            " |  __init__(self, mu=1, alpha=1, verbose=1)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  __solve_first_problem__(self)\n",
            " |  \n",
            " |  __solve_second_problem__(self)\n",
            " |  \n",
            " |  __verify_centering__(self, X, tolerance=1e-08)\n",
            " |  \n",
            " |  fit(self, X, y)\n",
            " |      Fit the HMLasso on (X, y).\n",
            " |      \n",
            " |      ------------\n",
            " |      Parameters:\n",
            " |          X : 2D numpy array, shape (n,p). It corresponds to the features, and\n",
            " |          must be mean-centered.\n",
            " |          y : 1D numpy array, shape (n,1) or (n,). It corresponds to the labels.\n",
            " |      \n",
            " |      Returns:\n",
            " |          None\n",
            " |  \n",
            " |  predict(self, X)\n",
            " |      Predict using the linear model.\n",
            " |      \n",
            " |      ------------\n",
            " |      Parameters:\n",
            " |          X : 2D numpy array\n",
            " |      \n",
            " |      Returns:\n",
            " |          y : 1D numpy array\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_Xy(n, p, replace_rate=0.3):\n",
        "  X = 100*np.random.rand(n,p) # Generate random X\n",
        "  y = 7*X[:, 0] - 2 * X[:, 1] + 5 * X[:, 2] + 19 * X[:, 3] + 6*X[:, 4]\n",
        "  \n",
        "  indices = np.full(X.shape, False, bool)\n",
        "  mask = np.random.choice([False, True], size=X.shape, p=((1 - replace_rate), replace_rate))\n",
        "  X[mask] = np.nan\n",
        "\n",
        "  return X, y\n",
        "\n",
        "X, y = get_Xy(10000, 300, 0.4)\n",
        "\n",
        "scaler = StandardScaler(with_std=False)\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "5mmg3-ifVCFy"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = HMLasso(mu=100, alpha=1, verbose=2)\n",
        "lasso.fit(X_scaled, y)\n",
        "X_test, y_test = get_Xy(10000, 300, replace_rate=0.)\n",
        "print(f\"error = {np.sqrt(mean_squared_error(y_test, lasso.predict(X_test)))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTsjf5XN8Kxe",
        "outputId": "c17e0f7b-e3fa-4af7-904d-91e6f39dc234"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Imputing parameters] Starting...\n",
            "[Imputing parameters] R calculated.\n",
            "[Imputing parameters] rho_pair calculated.\n",
            "[Imputing parameters] S_pair calculated.\n",
            "[Imputing parameters] Parameters imputed.\n",
            "[First Problem] Starting...\n",
            "[First Problem] Objective and constraints well-defined.\n",
            "[First Problem] Problem status: optimal.\n",
            "[First Problem] Problem solved.\n",
            "[Second Problem] Starting...\n",
            "[Second Problem] Objective and constraints well-defined.\n",
            "[Second Problem] Problem status: optimal.\n",
            "[Second Problem] Problem solved.\n",
            "\n",
            "Model fitted.\n",
            "error = 236.88176479846123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lasso.beta_opt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj690bA0i_tt",
        "outputId": "eb2ed5ea-d8b3-4555-f97a-0a8242b73c24"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7.13495908e+00, -1.78126439e+00,  5.43128186e+00,  1.95847919e+01,\n",
              "        6.07395216e+00,  6.70886094e-02, -1.00972082e-22,  8.22644747e-02,\n",
              "       -1.61471892e-02,  3.96495851e-22, -1.72657538e-21, -6.73026611e-22,\n",
              "       -2.13829266e-01, -2.60596534e-22, -2.93611047e-22, -2.22959195e-21,\n",
              "        9.76036875e-02, -9.14023444e-22,  3.51681820e-21,  9.31804465e-02,\n",
              "        2.46329568e-01,  9.75785753e-22, -9.56056252e-22, -7.06087482e-02,\n",
              "       -4.27133409e-01, -4.40831068e-01, -1.75340431e-01,  1.06622561e-01,\n",
              "       -7.96094961e-03, -2.35558160e-01, -1.35228797e-01, -2.54499128e-22,\n",
              "       -1.44093847e-01,  9.15040195e-02,  2.52981961e-22, -1.71967465e-01,\n",
              "       -3.83799881e-02, -2.66609289e-02, -1.57488510e-01,  3.29317312e-21,\n",
              "        9.62483102e-02, -2.69002943e-02, -2.84482812e-01,  1.95038187e-01,\n",
              "        2.77816850e-01, -2.61869241e-02,  3.12780047e-21,  7.93580101e-02,\n",
              "       -7.43277049e-02, -8.39906478e-02,  1.86537745e-21,  2.19799231e-22,\n",
              "        1.34274165e-22,  3.39617898e-01, -3.00676546e-01, -1.76062812e-21,\n",
              "       -1.00154541e-01, -5.60649819e-22, -6.60832581e-02, -6.05509740e-03,\n",
              "        5.77717655e-02, -1.89935514e-21, -1.64884468e-21, -2.38979654e-21,\n",
              "        5.52037813e-23, -1.21208012e-21,  1.94858589e-01,  2.72499335e-21,\n",
              "       -1.84439745e-01, -2.28457809e-21,  8.36962497e-22,  7.92933543e-23,\n",
              "        4.45789875e-22, -4.73268410e-22, -1.98649921e-21,  1.67651430e-01,\n",
              "        2.37705846e-01,  2.64646387e-02, -1.05435941e-01,  1.59244373e-02,\n",
              "        5.01658879e-22, -1.39025470e-21, -3.30641351e-01, -1.74006809e-01,\n",
              "        1.02795239e-21, -1.59459221e-21, -1.28342977e-01, -1.07943011e-21,\n",
              "       -4.72446238e-01,  4.24435872e-02, -4.11626285e-02,  7.68408097e-02,\n",
              "       -1.52085978e-01,  4.89777374e-22,  8.98433910e-02,  1.41470634e-01,\n",
              "       -3.03037311e-22, -2.57304035e-01, -1.50595749e-01,  8.28009037e-22,\n",
              "        6.68853768e-22,  1.29155777e-21, -1.82963627e-01,  7.01660492e-22,\n",
              "       -1.67444148e-01, -2.06391027e-02, -2.83887880e-21,  1.14291338e-01,\n",
              "        2.49291043e-01, -1.81085535e-21,  1.88251684e-21,  1.86839329e-01,\n",
              "        1.87963375e-01,  4.37935391e-02,  1.60662547e-01, -1.19473428e-01,\n",
              "        3.15919103e-01, -8.23603757e-22, -3.33055326e-01, -7.22699422e-22,\n",
              "       -1.28255105e-21, -2.14630473e-01,  1.88943724e-01, -7.97622967e-02,\n",
              "       -1.17035998e-22, -4.18154339e-22,  8.51103511e-02,  4.98402372e-03,\n",
              "       -1.82545196e-01, -1.02105799e-01,  6.48545213e-22,  4.73042747e-01,\n",
              "        3.87463624e-02,  4.77292617e-02, -1.07483928e-21, -2.24339169e-01,\n",
              "        9.48289320e-02, -3.58775079e-21, -4.93342494e-02, -2.82312433e-01,\n",
              "       -2.81742745e-01,  8.98493372e-02, -1.42322730e-21,  1.89606997e-21,\n",
              "       -8.59194368e-02,  8.15859858e-22,  7.87202371e-22, -8.90468559e-02,\n",
              "        1.36790577e-22, -6.21402512e-03, -7.11079146e-02, -3.70348036e-02,\n",
              "        8.82342109e-22, -2.32847336e-22, -8.34855084e-22,  2.15976784e-02,\n",
              "        7.03774821e-22, -1.10676301e-01, -9.57594582e-22,  3.75210113e-01,\n",
              "       -2.00245841e-01,  1.66043289e-01,  1.60659837e-21, -1.95526393e-01,\n",
              "        1.96057031e-01, -2.58080757e-01, -7.91411440e-02,  7.59116893e-22,\n",
              "       -3.78405155e-21, -2.63585468e-01,  8.75137756e-22,  2.14272930e-02,\n",
              "        7.56909567e-02,  1.23418604e-01,  2.78033379e-02, -1.29211296e-21,\n",
              "        1.28483769e-21, -1.02225824e-01,  1.65677283e-21,  2.97014462e-02,\n",
              "        1.22747510e-01, -1.36810928e-21,  3.32002507e-01,  8.30453380e-02,\n",
              "       -6.75196118e-22, -7.71900226e-02,  1.75547171e-01,  1.29762936e-01,\n",
              "        2.74029659e-21, -1.63632759e-01, -4.60156217e-03, -2.26792032e-21,\n",
              "        8.77322808e-02,  8.26983756e-22, -1.54108214e-02,  2.02537907e-01,\n",
              "       -2.55066949e-01, -2.74775792e-02, -3.19843902e-21, -3.61803724e-22,\n",
              "       -2.78909970e-22,  1.26048440e-21, -1.01824809e-01,  7.73679380e-22,\n",
              "        1.40563884e-21, -1.73805785e-21, -1.86780876e-01,  2.55814997e-02,\n",
              "        6.32382326e-02, -8.92714653e-23,  3.29167475e-22, -6.00476094e-02,\n",
              "        6.16419577e-22,  1.79304193e-21, -9.87960630e-02,  1.72861155e-21,\n",
              "        3.35888149e-01,  1.79829833e-02, -1.03439860e-01, -6.12377451e-02,\n",
              "       -2.52747904e-01,  3.48380035e-21, -1.04014796e-21,  2.24129850e-21,\n",
              "        4.17253337e-22, -1.23432878e-21, -2.28433999e-02, -1.27158101e-21,\n",
              "       -1.55500846e-01, -2.10463530e-02,  2.00258030e-21, -1.14260910e-22,\n",
              "        1.23451322e-01,  2.66143933e-22, -1.35099531e-21,  3.96856717e-01,\n",
              "        7.89634204e-02,  2.63712847e-01, -2.38727901e-21, -4.61296113e-22,\n",
              "        4.76771504e-23, -3.72720798e-22,  4.17143469e-02, -1.67331428e-21,\n",
              "       -1.30212315e-02,  8.89238327e-02, -3.94112663e-22,  1.90323528e-21,\n",
              "        2.26695178e-02,  1.75885383e-02,  6.33752601e-22, -2.13365768e-01,\n",
              "        1.79985000e-01,  2.30603491e-01, -8.06214068e-22, -1.19821656e-01,\n",
              "       -5.32742775e-23, -3.46957325e-21, -2.45814973e-02,  2.68143745e-21,\n",
              "        1.13048228e-21,  2.40373111e-01,  2.17975675e-01, -5.74450683e-04,\n",
              "        3.85052650e-01, -1.55197361e-21,  2.77145618e-01, -6.91335372e-02,\n",
              "        2.53485295e-21, -2.51496130e-01, -3.76197834e-01, -1.06141473e-01,\n",
              "        7.27149617e-03, -1.69324402e-01, -3.29877112e-22,  2.90620592e-21,\n",
              "       -1.06675515e-21, -4.84763816e-22, -4.88105076e-02,  8.25149393e-22,\n",
              "        2.40432805e-22,  3.66426472e-21,  2.48122588e-02, -4.28741685e-01,\n",
              "        3.08605291e-22, -2.44166713e-03, -1.82122015e-22, -5.33013110e-02,\n",
              "        2.37981110e-01,  2.33710088e-01, -3.04969202e-01,  2.88088399e-01,\n",
              "        1.65394304e-01, -5.33498646e-22, -2.00148192e-01,  3.39851722e-01,\n",
              "       -2.03837742e-01, -1.90176606e-21, -1.55086871e-01,  2.98285330e-01,\n",
              "       -4.04872562e-01,  2.39731162e-04, -2.24582001e-01,  4.21035261e-01,\n",
              "       -1.40862962e-21, -9.32860029e-02,  1.92582337e-01,  3.81970453e-01,\n",
              "        8.47082604e-22, -1.15145965e-23, -3.45225772e-02, -4.46580904e-01,\n",
              "       -1.34698292e-01,  1.60085253e-21, -1.97941966e-21, -7.70539330e-22,\n",
              "       -9.54657386e-02,  1.70746507e-22,  4.51978495e-02,  1.00298008e-01,\n",
              "        2.73342535e-01,  1.04760962e-21, -9.14344469e-02,  5.48916301e-02,\n",
              "       -1.31049577e-01, -4.54374563e-22, -6.44974014e-03, -3.43541798e-22,\n",
              "       -3.69346908e-21,  1.95497728e-21, -1.54324135e-01, -3.82261666e-22,\n",
              "       -2.94852005e-02, -4.02157056e-01, -1.68434610e-22, -7.81115212e-02,\n",
              "       -1.62125634e-01,  7.04415013e-02, -1.29174218e-01, -2.65117690e-01,\n",
              "       -1.08158497e-21, -9.82172057e-22,  9.50347644e-02, -4.22851180e-02,\n",
              "        5.92967630e-22, -1.72779835e-01, -4.60397176e-02, -6.66411411e-23,\n",
              "       -2.01009024e-22,  1.16785831e-02, -3.04511628e-01,  4.59176953e-01,\n",
              "        1.89434439e-02,  3.69873072e-02,  3.56039978e-21, -3.64921512e-01,\n",
              "       -1.12791409e-01, -1.16356811e-01, -1.77015509e-21, -4.44808811e-01,\n",
              "        5.31997267e-02,  1.77367984e-22,  1.28999592e-01,  1.40296412e-21,\n",
              "        3.10289012e-21,  2.66747878e-21, -1.21819497e-22,  2.07290219e-01,\n",
              "       -9.10467072e-22,  2.49179206e-22,  8.89257071e-02, -1.75942629e-21,\n",
              "       -3.60810473e-02, -1.38550087e-01, -1.95550663e-01,  1.65114102e-02,\n",
              "       -3.69142013e-23,  2.05405713e-21, -2.55880133e-22, -2.19528715e-21,\n",
              "        2.28237653e-21,  1.44349524e-01,  4.99071306e-02, -3.15106528e-02,\n",
              "        3.49804495e-01,  8.80058060e-23,  2.20543639e-21,  1.21142644e-01,\n",
              "        3.96434548e-02,  2.95174121e-01, -1.88239546e-21,  6.59344231e-02,\n",
              "       -2.08206013e-21,  4.52054970e-01, -2.21653755e-01,  1.08321123e-01,\n",
              "        8.08430169e-02,  2.79901397e-01,  2.23251853e-01,  1.27448492e-21,\n",
              "        1.58997745e-01, -2.79310020e-21, -1.70257144e-01,  1.17259692e-01,\n",
              "       -7.28116815e-22, -1.08521776e-21,  3.95282331e-01,  1.87114484e-01,\n",
              "        5.58967832e-22, -6.94618631e-02, -1.34649265e-01, -1.85937612e-21,\n",
              "        1.00102062e-01, -6.25475725e-02,  9.18084754e-02, -1.00866528e-01,\n",
              "        1.74894728e-02,  1.35318159e-01, -4.13693555e-01, -1.31429331e-01,\n",
              "        1.20114776e-01,  6.95554307e-02, -3.13801432e-22, -5.85830872e-22,\n",
              "        2.34611920e-21, -8.94365866e-22, -1.02459365e-22,  1.66216008e-01,\n",
              "       -2.39491736e-22, -2.88280464e-01, -2.80819463e-22, -4.21134035e-01,\n",
              "        9.28880918e-02,  7.28372898e-22,  1.47831781e-01,  7.22262275e-22,\n",
              "       -2.32481505e-01,  1.70635387e-21, -3.16044987e-01,  1.43309584e-01,\n",
              "        3.50110801e-02, -6.08193902e-02,  1.19771376e-21,  3.35269466e-01,\n",
              "       -6.17779402e-22,  1.12256896e-02, -7.25776659e-02, -3.56655951e-01,\n",
              "        2.12419464e-22,  5.94488286e-22,  1.07088956e-21, -3.09663988e-01,\n",
              "       -9.63390607e-02, -7.18399033e-02, -6.74104441e-02, -2.48726137e-01,\n",
              "        7.41673000e-22, -4.13855130e-01,  7.39130678e-23,  3.55333066e-22,\n",
              "        1.77823734e-01, -1.83235934e-01, -3.88724802e-02, -5.06240320e-03,\n",
              "       -3.89519246e-02, -3.02619387e-21,  7.34013010e-22,  3.68787577e-01,\n",
              "        5.73031207e-02, -1.87956759e-21, -7.10617213e-02,  1.67501778e-01,\n",
              "       -1.95972105e-21, -1.17689678e-21,  3.12158619e-02, -2.80822671e-21,\n",
              "       -1.73567927e-01, -4.99778686e-02,  1.10760485e-01,  7.29543352e-22,\n",
              "        1.99917317e-21,  3.32466119e-01,  1.01274104e-02,  2.44727063e-02,\n",
              "        8.77790137e-02, -1.94511401e-21,  5.14805275e-02,  1.37115503e-21,\n",
              "        1.56158844e-01,  3.23366699e-01,  1.14659979e-01,  1.06150280e-01,\n",
              "       -2.07414281e-21, -5.83726242e-02,  1.33555159e-21,  1.50943076e-21,\n",
              "       -6.14053544e-02,  5.19938259e-22,  9.79229229e-02, -1.78998810e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}